{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d436c465",
   "metadata": {},
   "source": [
    "# A Replication of BLP(1995)\n",
    "##### Last update: Dec. 2023 \n",
    "##### I sincerely thank Ivan Li (https://www.ivan-li.com/) for posting his code for reference. \n",
    "\n",
    "### This file replicates the following results in BLP(1995):\n",
    "\n",
    "* Table I: Descriptive Statistics\n",
    "* Table III: Results with Logit Demand and Marginal Cost Pricing\n",
    "* Table IV: Esimated Parameters of the Demand and Pricing Equations (column 3)\n",
    "* Table VI: A Sample of Estimated Own- and Cross-Price Semi-Elasticities\n",
    "\n",
    "### Content:\n",
    "\n",
    "1. [The Model](#1.-The-Model)\n",
    "1. [Estimation Procedure](#2.-Estimation-Procedure)\n",
    "1. [Define Functions](#3.-Define-Functions)\n",
    "1. [Replications](#4.-Replications)\n",
    "1. [Citations](#Citations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43895122",
   "metadata": {},
   "source": [
    "## 1. The Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79833c64",
   "metadata": {},
   "source": [
    "### Demand Side:\n",
    "Suppose there are $T$ markets (each market is a year), and $J_t$ products in each market $t$.\n",
    "\n",
    "For each consumer $i$, his utility for purchasing product $j$ in market $t$ is given by:\n",
    "\n",
    "$$\n",
    "u_{ijt} = \\alpha log(y_i-p_j) + x_{jt}'\\beta_i + \\xi_{jt} + \\epsilon_{ijt}\n",
    "$$\n",
    "\n",
    "where $y_i$ is his income, $p_j$ is price, $x_{jt}$ is a vector of observable product characteristics, $\\xi_{jt}$ is the unobservable average utility from consuming product $j$ in the population, and $\\epsilon_{ijt}$ is the idiosyncratic error term. \n",
    "\n",
    "Note that, the coefficient $\\beta_i$ is individual-specific. We may interested in the \"average taste\" for the total population. Hence, we decompose it into two parts and rewrite our utility representation:\n",
    "\n",
    "\\begin{align}\n",
    "u_{ijt} &= \\alpha log(y_i-p_j) + x_{jt}'\\bar\\beta + \\sum_k\\sigma_kx_{jk}v_{ik} + \\xi_{jt} +  \\epsilon_{ijk} \\\\\n",
    "        &= \\alpha log(y_i-p_j) + \\delta_{jt} +  \\sum_k\\sigma_kx_{jk}v_{ik} +  \\epsilon_{ijk}\n",
    "\\end{align}\n",
    "\n",
    "where $\\delta_{jt} =x_{jt}'\\bar\\beta + \\xi_{jt}  $ is the mean utility, $(\\zeta_i,\\epsilon_i) = (v_{i1},...v_{ik};\\epsilon_{i0},...\\epsilon_{iJ})$ are random variables with mean zero. In this practice, we assume $\\zeta_i$ is standard normal and $\\epsilon_i$ is T1EV.\n",
    "\n",
    "One caveat is that, when $y_i<p_i$, e.g. a worker's income is less than the price of an expensive car, this will cause a problem. Therefore, we modify the utiliy function as:\n",
    "\n",
    "\\begin{align}\n",
    "u_{ijt} &= \\delta_{jt} +  \\sum_k\\sigma_kx_{jk}v_{ik} +  \\epsilon_{ijk} -\\alpha \\frac{p_{jt}}{y_i}\n",
    "\\end{align}\n",
    "\n",
    "For the outside good (not buying):\n",
    "\\begin{align}\n",
    "    u_{i0t} = \\alpha log(y_i) + \\xi_0 + \\sigma_0v_{i0} + \\epsilon_{io},  \\forall t \\in T\n",
    "\\end{align}\n",
    "\n",
    "The mean utility of outside good is normalized to 0 for simplicity.\n",
    "\n",
    "The parameters of interest $\\theta = \\{\\theta_1, \\theta_2\\}$ has two parts: Ones that for population $\\theta_1 = \\bar\\beta$ (since it can be estimated in a linear form, it is called \"linear parameters\"), and ones for idiosyncratic variances $\\theta_2 = \\{\\alpha; \\sigma_1,...\\sigma_k\\}$ (we call them \"nonlinear parameters\").\n",
    "\n",
    "\n",
    "Since $\\epsilon$ is T1EV and each consumer can only buy one good, the predicted market share is then given by a mixed logit form:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat s_{jt} &= \\int\\mathbb1\\{u_{ijt}\\geq u_{ikt}, \\forall k\\neq j\\}dF(y_i, \\zeta_i) \\\\\n",
    "       &= \\int \\frac{exp\\{\\alpha log(y_i-p_j) + \\delta_{jt} + \\sum_k\\sigma_kx_{jk}v_{ik} \\} }{1 + \\sum_{l=1}^Jexp\\{\\alpha log(y_i-p_l) + \\delta_{lt} + \\sum_k\\sigma_kx_{lk}v_{ik} \\}}dF(y_i, \\zeta_i)\\\\\n",
    "       &\\approx \\sum_{i=1}^{NS}\\frac{exp\\{\\alpha log(y_i-p_j) + \\delta_{jt} + \\sum_k\\sigma_kx_{jk}v_{ik} \\} }{1 + \\sum_{l=1}^Jexp\\{\\alpha log(y_i-p_l) + \\delta_{lt} + \\sum_k\\sigma_kx_{lk}v_{ik} \\}}\n",
    "\\end{align}\n",
    "\n",
    "where NS is the number of simulation draws in each market.\n",
    "\n",
    "Actually, real market share $s_{jt}$ is observable and we should let our predicted share equalize the real share $\\hat s_{jt} = s_{jt}$.\n",
    "\n",
    "\n",
    "Note that, $\\hat s_{jt}(\\delta_{jt})$ is a function of $\\delta_{jt}$, and we can invert it to obtain a constraction mapping (which is proved by BLP(1995)):\n",
    "\n",
    "\\begin{align}\n",
    "\\delta_{jt}^{h+1} = \\delta_{jt}^h + ln(s_{jt}) - ln(\\hat s_{jt}(\\delta_{jt}^h))\n",
    "\\end{align}\n",
    "\n",
    "Hence, given nonlinear parameters $\\theta$, we can obtain the mean utility $\\delta$, which furthermore implies a linear equation  $\\delta_{jt} =x_{jt}'\\bar\\beta + \\xi_{jt}  $. We can run regression to obtain the linear parameters $\\bar\\beta$.\n",
    "\n",
    "However, $\\mathbb E[\\xi_{jt}|x_{jt}] \\neq 0$ brings the endogeneity problem. We use characterstics of other goods in the same market as instruments $Z_{d}$ suggested by BLP(1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e852428",
   "metadata": {},
   "source": [
    "### Supply Side:\n",
    "\n",
    "We assume there are $F$ firms, each of which product a subset $\\mathcal J_f$ of the $J$ goods. The cost characteristics are decomposed into a subset which is observed by econometrician $w_j$, and an unobserved component $\\omega_j$. Note that $x_j$ for consumers may be part of $w_j$, and $\\omega_j$ is correlated with $\\xi_j$. \n",
    "\n",
    "We assume the marginal cost of good $j$ can be written as:\n",
    "\\begin{align}\n",
    "ln(mc_j) = w_j\\gamma+\\omega_j\n",
    "\\end{align}\n",
    "where $\\gamma$ is a vector of parameters to be estimated.\n",
    "\n",
    "The profit of firm $f$ is given by:\n",
    "\\begin{align}\n",
    "\\Pi_f = \\sum_{j\\in\\mathcal J_f} (p_j-mc_j)\\cdot Ms_j(p,x,\\xi,\\theta)\n",
    "\\end{align}\n",
    "\n",
    "where $M$ is the total number of consumers at a given market.\n",
    "\n",
    "Our FOC is then\n",
    "\\begin{align}\n",
    "s_j + \\sum_{r\\in\\mathcal J_f}(p_r-mc_r)\\frac{\\partial s_r}{\\partial p_j} = 0, \\forall j\\in\\mathcal J_f\n",
    "\\end{align}\n",
    "\n",
    "This implies the price-cost markups $b(p,x,\\xi,\\theta) = p-mc$ can be expressed as:\n",
    "\\begin{align}\n",
    "b(p,x,\\xi,\\theta) = \\Omega^{-1}s(p,x,\\xi,\\theta)\n",
    "\\end{align}\n",
    "\n",
    "where $\\Omega_{jr} = -\\frac{\\partial s_r}{\\partial p_j}$ if $r$ and $j$ are produced by the same firm and $\\Omega_{jr} = 0$ otherwise.\n",
    "\n",
    "Hence, we have the regression equation as\n",
    "\n",
    "\\begin{align}\n",
    "ln(p-b(p,x,\\xi,\\theta) ) = w\\gamma+\\omega\n",
    "\\end{align}\n",
    "\n",
    "Notice that, we still need to instrumenting for $w$ since cost characteristics may be correlated to unobserved disturbance. BLP uses all other products' characteristics as instrument $Z_s$ since products that face good substitudes will tend to have lower markups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e1caba",
   "metadata": {},
   "source": [
    "## 2. Estimation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43a8e8",
   "metadata": {},
   "source": [
    "We do the estimation using **Nested Fixed Point Algorithm**:\n",
    "\n",
    "Outer loop: Search over nonlinear parameters $\\theta_2$\n",
    "\n",
    "Inner loop: for given $\\theta_2$:\n",
    "* Use contraction mapping to find mean utilities $\\hat\\delta$ given market share $s$\n",
    "* Use $\\hat\\delta$ and the demand instrument $Z_d$ to find linear paramters $\\hat\\theta_1$ and residual $\\hat\\xi$\n",
    "* Compute markup $b(\\theta)$, use it and the supply instrument $Z_s$ to run IV regression to find $\\hat\\omega$\n",
    "* Form the GMM objective function of $\\hat \\theta = \\text{argmin}_{\\theta\\in\\Theta} Z'\\hat {G}'W\\hat GZ$, where $Z = (Z'_d, Z'_s)'$ and $\\hat G = (\\hat{\\xi}', \\hat{\\omega}')'$, since IVs are orthogonal to error terms.\n",
    "\n",
    "Note that, we need to conduct 2-step GMM since we need to obtain the optimal weighting matrix from the first step. \n",
    "\n",
    "The inital weighting matrix is set to $W_0 = ZZ'$ following the suggestion in appendix of Nevo's practitioners' guide.\n",
    "\n",
    "The (feasible) optimal weighting matrix is $\\tilde W = Z'\\hat {G}'\\hat GZ$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b601c",
   "metadata": {},
   "source": [
    "## 3. Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298c0788",
   "metadata": {},
   "source": [
    "We first import data and create required variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d82d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from scipy.optimize import minimize\n",
    "from numba import jit, njit, prange\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b9916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelvec</th>\n",
       "      <th>newmodv</th>\n",
       "      <th>model_year</th>\n",
       "      <th>id</th>\n",
       "      <th>firmid</th>\n",
       "      <th>market</th>\n",
       "      <th>hpwt</th>\n",
       "      <th>space</th>\n",
       "      <th>air</th>\n",
       "      <th>mpd</th>\n",
       "      <th>...</th>\n",
       "      <th>ln_space</th>\n",
       "      <th>ln_mpg</th>\n",
       "      <th>ln_mpd</th>\n",
       "      <th>ln_price</th>\n",
       "      <th>trend</th>\n",
       "      <th>cons</th>\n",
       "      <th>s_0</th>\n",
       "      <th>s_i</th>\n",
       "      <th>diff</th>\n",
       "      <th>diff_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMGREM</td>\n",
       "      <td>AMGREM71</td>\n",
       "      <td>71</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528997</td>\n",
       "      <td>1.1502</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139936</td>\n",
       "      <td>0.528862</td>\n",
       "      <td>0.635595</td>\n",
       "      <td>1.596515</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127713</td>\n",
       "      <td>-6.858013</td>\n",
       "      <td>-6.730300</td>\n",
       "      <td>-6.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMHORN</td>\n",
       "      <td>AMHORN71</td>\n",
       "      <td>71</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494324</td>\n",
       "      <td>1.2780</td>\n",
       "      <td>0</td>\n",
       "      <td>1.935989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245296</td>\n",
       "      <td>0.553885</td>\n",
       "      <td>0.660618</td>\n",
       "      <td>1.707662</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127713</td>\n",
       "      <td>-7.308233</td>\n",
       "      <td>-7.180520</td>\n",
       "      <td>-7.180520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMJAVL</td>\n",
       "      <td>AMJAVL71</td>\n",
       "      <td>71</td>\n",
       "      <td>132</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467613</td>\n",
       "      <td>1.4592</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>0.540462</td>\n",
       "      <td>1.961311</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127713</td>\n",
       "      <td>-7.983628</td>\n",
       "      <td>-7.855915</td>\n",
       "      <td>-7.855915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMMATA</td>\n",
       "      <td>AMMATA71</td>\n",
       "      <td>71</td>\n",
       "      <td>134</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426540</td>\n",
       "      <td>1.6068</td>\n",
       "      <td>0</td>\n",
       "      <td>1.687871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474245</td>\n",
       "      <td>0.416735</td>\n",
       "      <td>0.523468</td>\n",
       "      <td>1.922716</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127713</td>\n",
       "      <td>-7.557843</td>\n",
       "      <td>-7.430130</td>\n",
       "      <td>-7.430130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAMBS</td>\n",
       "      <td>AMAMBS71</td>\n",
       "      <td>71</td>\n",
       "      <td>136</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>1.6458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.504286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.301585</td>\n",
       "      <td>0.408318</td>\n",
       "      <td>2.189237</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.127713</td>\n",
       "      <td>-7.724201</td>\n",
       "      <td>-7.596488</td>\n",
       "      <td>-7.596488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelvec   newmodv  model_year   id  firmid  market      hpwt   space  air  \\\n",
       "0   AMGREM  AMGREM71          71  129      15       1  0.528997  1.1502    0   \n",
       "1   AMHORN  AMHORN71          71  130      15       1  0.494324  1.2780    0   \n",
       "2   AMJAVL  AMJAVL71          71  132      15       1  0.467613  1.4592    0   \n",
       "3   AMMATA  AMMATA71          71  134      15       1  0.426540  1.6068    0   \n",
       "4   AMAMBS  AMAMBS71          71  136      15       1  0.452489  1.6458    0   \n",
       "\n",
       "        mpd  ...  ln_space    ln_mpg    ln_mpd  ln_price  trend  cons  \\\n",
       "0  1.888146  ...  0.139936  0.528862  0.635595  1.596515     71     1   \n",
       "1  1.935989  ...  0.245296  0.553885  0.660618  1.707662     71     1   \n",
       "2  1.716799  ...  0.377888  0.433729  0.540462  1.961311     71     1   \n",
       "3  1.687871  ...  0.474245  0.416735  0.523468  1.922716     71     1   \n",
       "4  1.504286  ...  0.498227  0.301585  0.408318  2.189237     71     1   \n",
       "\n",
       "        s_0       s_i      diff    diff_2  \n",
       "0 -0.127713 -6.858013 -6.730300 -6.730300  \n",
       "1 -0.127713 -7.308233 -7.180520 -7.180520  \n",
       "2 -0.127713 -7.983628 -7.855915 -7.855915  \n",
       "3 -0.127713 -7.557843 -7.430130 -7.430130  \n",
       "4 -0.127713 -7.724201 -7.596488 -7.596488  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataframe\n",
    "df = pd.read_csv(\"blp_1995_data.csv\")\n",
    "df = df.drop(df.columns[0], axis = 1)\n",
    "\n",
    "# log transformation of variables\n",
    "df[[\"ln_hpwt\", \"ln_space\", \"ln_mpg\", \"ln_mpd\", \"ln_price\"]] = \\\n",
    "df[[\"hpwt\", \"space\", \"mpg\", \"mpd\", \"price\"]].apply(lambda x: np.log(x))\n",
    "\n",
    "df[\"trend\"] = df.market.map(lambda x: x+70) # set the value of trend = year\n",
    "df[\"cons\"] = 1\n",
    "df[\"s_0\"] = np.log(df.share_out)\n",
    "df[\"s_i\"] = np.log(df.share)\n",
    "\n",
    "df[\"diff\"] = df.s_i - df.s_0\n",
    "df[\"diff_2\"] = np.log(df.share) - np.log(df.share_out)\n",
    "df[\"ln_price\"] = np.log(df.price)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d87e6",
   "metadata": {},
   "source": [
    "For demand side, product characteristics $X$ includes HP/Weight, air, MP$, space and a constant.\n",
    "\n",
    "For supply side, cost characteristics $W$ includes ln(HP/Weight), ln(MPG), ln(space), air, trend and a constant.\n",
    "\n",
    "Also, we obtain income means for 20 markets (years) and a standard deviation of income from CPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f85ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand side characteristics\n",
    "X_d = df[[\"cons\", \"hpwt\", \"air\", \"mpd\", \"space\"]].values\n",
    "\n",
    "# supply side characteristics\n",
    "X_s = df[[\"cons\", \"ln_hpwt\", \"air\", \"ln_mpg\", \"ln_space\", \"trend\"]].values\n",
    "\n",
    "# price\n",
    "p = df.price.values\n",
    "\n",
    "# number of goods per markets (J_t)\n",
    "J = df.groupby(\"year\").sum().cons.values\n",
    "\n",
    "# number of markets (T)\n",
    "T = len(J)\n",
    "\n",
    "# number of draws per market\n",
    "N = 1000\n",
    "\n",
    "# estimated log(income) means and standard deviation for years 1971 - 1990 (from CPS)\n",
    "income_means = [2.01156, 2.06526, 2.07843, 2.05775, 2.02915, 2.05346, 2.06745,\n",
    "               2.09805, 2.10404, 2.07208, 2.06019, 2.06561, 2.07672, 2.10437, 2.12608, 2.16426,\n",
    "               2.18071, 2.18856, 2.21250, 2.18377]\n",
    "income_std = 1.72\n",
    "\n",
    "# number of non-linear parameters = 6\n",
    "# they are coefficients for {constant, hp/wt, air, mp$, size, price}\n",
    "k = 6\n",
    "\n",
    "# market for ijt\n",
    "markets = df.market.values\n",
    "\n",
    "# unique markets\n",
    "unique_mkts = np.unique(df.market)\n",
    "\n",
    "# firms\n",
    "firms = np.reshape(df.firmid.values, (-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95fc26",
   "metadata": {},
   "source": [
    "I. Simulate $N$ individuals' income $y_{i}$ for each market $t$. \n",
    "\n",
    "We assume $y_i$ is log-normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f9b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "\n",
    "# repeat values in income_means for N times\n",
    "m_t = np.repeat(income_means, N)\n",
    "\n",
    "# matrix of simulated values\n",
    "V = np.reshape(np.random.standard_normal(k*N*T), (T*N,k))\n",
    "\n",
    "# we use different draws per market\n",
    "y_it = np.exp(m_t + income_std * V[:, k-1]).reshape(T,N).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23758be1",
   "metadata": {},
   "source": [
    "II. Define a function to compute the predicted markets share $\\hat s_{jt}$ given required data and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f584dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loops that calculate utility in a separate function so that it can be run in parallel \n",
    "@jit\n",
    "def utility_iter(output, x, v, p, y, delta, theta_2, J, T, N):\n",
    "    # iterate over individuals\n",
    "    for i in prange(N):\n",
    "        # iterate over every product in every market\n",
    "        tj = 0\n",
    "        for t in prange(T):\n",
    "            # market size of market t\n",
    "            mkt_size = J[t]\n",
    "            \n",
    "            # income for individual i in market t\n",
    "            y_im = y[i, t]\n",
    "            \n",
    "            for j in prange(mkt_size):\n",
    "                output[tj, i] = delta[tj] + \\\n",
    "                    v[N * t + i, 0] * theta_2[0] * x[tj, 0] + \\\n",
    "                    v[N * t + i, 1] * theta_2[1] * x[tj, 1] + \\\n",
    "                    v[N * t + i, 2] * theta_2[2] * x[tj, 2] + \\\n",
    "                    v[N * t + i, 3] * theta_2[3] * x[tj, 3] + \\\n",
    "                    v[N * t + i, 4] * theta_2[4] * x[tj, 4] - \\\n",
    "                    theta_2[5] * p[tj] / y_im\n",
    "                \n",
    "                tj += 1\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa58406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  this function computes indirect utility given parameters\n",
    "#  x: matrix of demand characteristics\n",
    "#  v: monte carlo draws of N simulations\n",
    "#  p: price vector\n",
    "#  y: income of individuals\n",
    "#  delta: guess for the mean utility\n",
    "#  theta_2: non-linear parameters\n",
    "#  J: vector of number of goods per market\n",
    "#  T: numer of markets\n",
    "#  N: number of simulations\n",
    "#  it returns a matrix (J*T, N) to store the simulated utilities\n",
    "@jit\n",
    "def compute_indirect_utility(x, v, p, y, delta, theta_2, J, T, N):\n",
    "    # make sure theta_2 is positive\n",
    "    theta_2 = np.abs(theta_2)\n",
    "    \n",
    "    # predefine output matrix\n",
    "    simulated_u = np.zeros((sum(J), N))\n",
    "    \n",
    "    simulated_u = utility_iter(simulated_u, x, v, p, y, delta, theta_2, J, T, N)\n",
    "                \n",
    "    return simulated_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14ac1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function compute shares for all goods in all market\n",
    "\n",
    "@jit\n",
    "def compute_share(x, v, p, y, delta, theta_2, J, T, N):\n",
    "    # predefine the matrix of individual shares\n",
    "    q = np.zeros((np.sum(J), N))\n",
    "    \n",
    "    # obtain vector of indirect utilities\n",
    "    u = compute_indirect_utility(x, v, p, y, delta, theta_2, J, T, N)\n",
    "    \n",
    "    # exponentiate the utilities\n",
    "    exp_u = np.exp(u)\n",
    "    \n",
    "    # pointer to the first good in market t\n",
    "    first_good = 0\n",
    "    \n",
    "    for t in range(T):\n",
    "        mkt_size = J[t]\n",
    "        numerator = exp_u[first_good:first_good + mkt_size, :]\n",
    "        denominator = 1 + numerator.sum(axis = 0)\n",
    "        q[first_good:first_good + mkt_size, :] = numerator/denominator\n",
    "        first_good += mkt_size\n",
    "        \n",
    "    # We assume each simulation carries the same weight\n",
    "    # Then the predicted share is simply the average of individual shares\n",
    "    s = np.matmul(q, np.repeat(1/N, N))  \n",
    "        \n",
    "    return [q,s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca11c6c",
   "metadata": {},
   "source": [
    "III. Define the function that uses contraction mapping to find $\\delta_{jt}$ given $s_{jt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e545260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class so I can repeatedly update the delta value\n",
    "class delta:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "# initialize a delta object using the delta_0 values\n",
    "delta_0 = df.diff_2.values\n",
    "d = delta(delta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629b7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def solve_delta(s, x, v, p, y, delta, theta_2, J, T, N, tol):\n",
    "    # define the initial tolerance value\n",
    "    eps = 10\n",
    "    \n",
    "    # initialize delta\n",
    "    delta_old = delta\n",
    "    \n",
    "    while eps > tol:\n",
    "        # extract shares\n",
    "        output = compute_share(x, v, p, y, delta_old, theta_2, J, T, N)\n",
    "        s_hat = output[1]\n",
    "        \n",
    "        # contraction mapping\n",
    "        delta_new = delta_old + np.log(s/s_hat)\n",
    "        \n",
    "        # update tolerance\n",
    "        eps = np.max(np.abs(delta_new - delta_old))\n",
    "        #print(eps)\n",
    "        \n",
    "        # update delta\n",
    "        delta_old = delta_new.copy()\n",
    "        \n",
    "        return delta_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7556db8",
   "metadata": {},
   "source": [
    "IV. Define a function to compute marginal cost:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f514f2d",
   "metadata": {},
   "source": [
    "Recall that, $s_j\\approx \\frac{1}{NS}\\sum_{i=1}^{NS}\\frac{exp(\\tilde u_{ij})}{1+\\sum_{k=1}^{J}exp(\\tilde u_{ik})}$, where $\\tilde u_{ij} = \\delta_{j} +  \\sum_k\\sigma_kx_{jk}v_{ik} -\\alpha \\frac{p_{j}}{y_i}$ is the indirect utility net of logit shock.\n",
    "\n",
    "Then $\\frac{\\partial s_{j}}{\\partial p_j} = \\frac{1}{NS}\\sum_{i=1}^{NS}\\frac{\\alpha}{y_i}(s_{ij}^2-s_{ij})$ and $\\frac{\\partial s_{j}}{\\partial p_k} = \\frac{1}{NS}\\sum_{i=1}^{NS}\\frac{\\alpha}{y_i} s_{ij} s_{ik}$, where $s_{ij}$ is the individual share of consumer $i$ on product $j$.\n",
    "\n",
    "Write in matrix form, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\Omega \\approx \\frac{1}{NS}\\sum_{i=1}^{NS}\\frac{\\alpha}{y_i}\\cdot \\mathcal H \\cdot (s_i s_i'-diag(s_i)) \n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathcal H$ is the ownership matrix, and $s_i$ is the indivual share of simulated consumer $i$.\n",
    "\n",
    "After obtaining $\\Omega$, we can compute marginal cost by:\n",
    "\\begin{align*}\n",
    "mc = p-b = p - \\Omega^{-1}s\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6efb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def compute_mc(q_s, firms, p, y, alpha, J, T, N, unique_mkts, markets):\n",
    "    \n",
    "    # predefine output vector\n",
    "    marginal_cost = np.zeros(np.sum(J))\n",
    "    \n",
    "    # make sure the value of alpha is positive\n",
    "    alpha = np.abs(alpha)\n",
    "    \n",
    "    # individual shares\n",
    "    q = q_s[0]\n",
    "    \n",
    "    # predicted shares\n",
    "    s = q_s[1].reshape((-1,1))\n",
    "    \n",
    "    # reshape the price vector\n",
    "    p = p.reshape((-1,1))\n",
    "    \n",
    "    # iterate over markets\n",
    "    for m in unique_mkts:\n",
    "        # obtain list of firms operating in that market/year\n",
    "        firm_yr = firms[markets == m]\n",
    "        \n",
    "        # obtain list of prices of goods in that market/year\n",
    "        price = p[markets == m]\n",
    "        \n",
    "        # J_t x J_t block matrix of 1's indicating goods belonging to same firm in that market/year\n",
    "        # also known as the ownership matrix\n",
    "        ownership = np.equal(firm_yr, np.transpose(firm_yr))\n",
    "        \n",
    "        # obtain matrix of individual shares for all simulations and all goods in that market/year\n",
    "        q_m = q[markets == m,:]\n",
    "        \n",
    "        # number of products in that market\n",
    "        no_of_products = np.size(q_m,0)\n",
    "        \n",
    "        # predefine the Omega matrix (cross-price derivative matrix w.r.t. ownership matrix)\n",
    "        gradient = np.zeros((no_of_products, no_of_products))\n",
    "        \n",
    "        for i in range(N):\n",
    "            q_mi = q_m[:,i].reshape((-1,1))\n",
    "            gradient += (1/N) * alpha/y[i, m-1] * ownership * (q_mi @ q_mi.T - np.diag(q_m[:,i]))\n",
    "        \n",
    "        \n",
    "        b = np.linalg.inv(-gradient)@s[markets == m]\n",
    "        mc = price - b\n",
    "        mc[mc < 0] = 0.001\n",
    "        \n",
    "        marginal_cost[markets == m] = mc.flatten()\n",
    "        \n",
    "        \n",
    "    return marginal_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cd0d9",
   "metadata": {},
   "source": [
    "V. Define a function to generate instruments used by BLP(1995):\n",
    "\n",
    "The instrument has two parts:\n",
    "\n",
    "total_firms contains a vector of all summed product/cost characteristics produced by the same firm.\n",
    "\n",
    "total_mkts contains a vector of all summed product/cost characteristics produced by all firms in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138dff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_iv(char, firms, unique_mkts, markets):\n",
    "    # predefine demand and supply sides instruments\n",
    "    total_mkts = np.zeros((np.size(char, axis = 0), np.size(char, axis = 1)))\n",
    "    total_firms = np.zeros((np.size(char, axis = 0), np.size(char, axis = 1)))\n",
    "    \n",
    "    for m in unique_mkts:\n",
    "        sub = char[markets == m, :]\n",
    "        firm_info = firms[markets == m]\n",
    "        ownership = np.equal(firm_info, np.transpose(firm_info))\n",
    "        \n",
    "        z_1 = np.zeros((np.size(sub, axis = 0), np.size(sub, axis = 1)))\n",
    "        z_2 = np.zeros((np.size(sub, axis = 0), np.size(sub, axis = 1)))\n",
    "        \n",
    "        for i in range(np.size(sub, axis = 1)):\n",
    "            z_1[:,i] = (sub[:,i].reshape((-1,1)) * ownership).T.sum(axis=0)\n",
    "            \n",
    "        total_firms[markets == m, :] = z_1\n",
    "        \n",
    "        for i in range(np.size(sub, axis = 1)):\n",
    "            z_2[:,i] = (sub[:,i].reshape((-1,1)) * (ownership + np.logical_not(ownership))).sum(axis=0)\n",
    "            \n",
    "        total_mkts[markets == m, :] = z_2\n",
    "        \n",
    "    return [total_firms, total_mkts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4806e3f",
   "metadata": {},
   "source": [
    "VI: Define objective function that can search over nonlinear parameters $\\theta_2$:\n",
    "\n",
    "Step 1: Given non-linear paramerters $\\theta_2$, actual market share $s$, solve the optimal $\\hat\\delta$\n",
    "\n",
    "Step 2: Compute log marginal cost $log(mc)$. \n",
    "\n",
    "Step 3: Stack $\\mathbf y = (\\hat\\delta', log(mc)')'$, $X = (X_d', X_s')'$, $Z = (Z_d', Z_s')'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf43c8a",
   "metadata": {},
   "source": [
    "Step 4: Obtain the linear paramter $\\hat\\theta_1 = (X'ZWZ'X)^{-1}X'ZWZ'Y$ by GMM:\n",
    "\n",
    "  Note that we have $\\mathbb E[z_i(y_i-x_i'\\theta_1)] = 0$\n",
    "  \n",
    "  Then we have the sample analog $\\frac{1}{N}Z'Y-\\frac{1}{N}Z'X\\theta_1 = 0$. However, since $d_z>d_{\\theta_1}$, this is a over-identified linear system, the equality cannot hold. We can estimate $\\theta_1$ using GLS (Generalized Least Squares):\n",
    "  \n",
    "  Denote $\\eta = Z'Y$, $G = Z'X$, the previous equation can be written as $\\eta = G\\theta_1 + u$. The estimates of $\\theta_1$ is $\\hat\\theta_1 = (G'WG)^{-1}G'W\\eta$, which is equivalent to $\\hat\\theta_1 = (X'ZWZ'X)^{-1}X'ZWZ'Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4dba1a",
   "metadata": {},
   "source": [
    "Step 5: obtain the residual $\\hat\\xi = \\mathbf y - X\\hat\\theta_1$\n",
    "\n",
    "Step 6: $\\theta_2 = \\text{argmin}_{\\theta\\in\\Theta}\\hat\\xi'Z W Z'\\hat\\xi$ using $\\mathbb E[Z'\\xi] = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0242580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_fcn(theta_2, s, X_d, V, p, y, J, T, N, unique_mkts, markets, tol, \n",
    "              Z_d, Z_s, X_s, w, firms):\n",
    "    \n",
    "    obs = np.sum(J)\n",
    "    \n",
    "    # find the converged delta value\n",
    "    d.delta = solve_delta(s, X_d, V, p, y, d.delta, theta_2, J, T, N, tol)\n",
    "    \n",
    "    # obtain individual shares and actual shares from delta\n",
    "    q_s = compute_share(X_d, V, p, y, d.delta, theta_2, J, T, N)\n",
    "    \n",
    "    # compute marginal costs\n",
    "    mc = compute_mc(q_s, firms, p, y, theta_2[5], J, T, N, unique_mkts, markets).reshape((-1,1))\n",
    "\n",
    "    # stack both demand and supply side variables\n",
    "    y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))\n",
    "\n",
    "    # create characteristics matrix that includes both supply and demand side\n",
    "    # with demand characteristics on the top left and supply on the bottom right\n",
    "    x = scipy.linalg.block_diag(X_d,X_s)\n",
    "\n",
    "    # create matrix of supply and demand instruments, again with\n",
    "    #  demand instruments on the right and supply on the left (top/down changed)\n",
    "    z = scipy.linalg.block_diag(Z_d,Z_s)\n",
    "\n",
    "    # get linear parameters\n",
    "    theta_1 = np.linalg.inv(x.T @ z @ w @ z.T @ x) @ (x.T @ z @ w @ z.T @ y2)\n",
    "\n",
    "    # get the error term xi\n",
    "    xi_w = y2 - x @ theta_1\n",
    "\n",
    "    # compute g_bar in GMM\n",
    "    g = z.T @ xi_w\n",
    "\n",
    "    obj = float(g.T @ w @ g)\n",
    "    \n",
    "    #print([theta_2, obj])\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e20f51",
   "metadata": {},
   "source": [
    "### 4. Replications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca37513",
   "metadata": {},
   "source": [
    "#### Table I: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e6a49d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Models</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Japan</th>\n",
       "      <th>European</th>\n",
       "      <th>HP/Wt</th>\n",
       "      <th>Size</th>\n",
       "      <th>Air</th>\n",
       "      <th>MPG</th>\n",
       "      <th>MP$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>92</td>\n",
       "      <td>86.892</td>\n",
       "      <td>7.868</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.496</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>89</td>\n",
       "      <td>98.623</td>\n",
       "      <td>7.979</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.391</td>\n",
       "      <td>1.510</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.619</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>86</td>\n",
       "      <td>92.785</td>\n",
       "      <td>7.535</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.529</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.589</td>\n",
       "      <td>1.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>72</td>\n",
       "      <td>105.119</td>\n",
       "      <td>7.506</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1.510</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1.567</td>\n",
       "      <td>1.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>93</td>\n",
       "      <td>84.775</td>\n",
       "      <td>7.821</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.337</td>\n",
       "      <td>1.479</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1.584</td>\n",
       "      <td>1.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>99</td>\n",
       "      <td>93.382</td>\n",
       "      <td>7.787</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.338</td>\n",
       "      <td>1.508</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>95</td>\n",
       "      <td>97.727</td>\n",
       "      <td>7.651</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.467</td>\n",
       "      <td>0.032</td>\n",
       "      <td>1.947</td>\n",
       "      <td>1.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>95</td>\n",
       "      <td>99.444</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.346</td>\n",
       "      <td>1.405</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1.982</td>\n",
       "      <td>1.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>102</td>\n",
       "      <td>82.742</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.348</td>\n",
       "      <td>1.343</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.061</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>103</td>\n",
       "      <td>71.567</td>\n",
       "      <td>7.718</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.078</td>\n",
       "      <td>2.215</td>\n",
       "      <td>1.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>116</td>\n",
       "      <td>62.030</td>\n",
       "      <td>8.349</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.094</td>\n",
       "      <td>2.363</td>\n",
       "      <td>1.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>110</td>\n",
       "      <td>61.893</td>\n",
       "      <td>8.831</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1.277</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.440</td>\n",
       "      <td>1.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>115</td>\n",
       "      <td>67.878</td>\n",
       "      <td>8.821</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.126</td>\n",
       "      <td>2.601</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>113</td>\n",
       "      <td>85.933</td>\n",
       "      <td>8.870</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.293</td>\n",
       "      <td>0.129</td>\n",
       "      <td>2.469</td>\n",
       "      <td>2.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>136</td>\n",
       "      <td>78.143</td>\n",
       "      <td>8.938</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.265</td>\n",
       "      <td>0.140</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>130</td>\n",
       "      <td>83.756</td>\n",
       "      <td>9.382</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.379</td>\n",
       "      <td>1.249</td>\n",
       "      <td>0.176</td>\n",
       "      <td>2.416</td>\n",
       "      <td>2.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>143</td>\n",
       "      <td>67.667</td>\n",
       "      <td>9.965</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.246</td>\n",
       "      <td>0.229</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>150</td>\n",
       "      <td>67.078</td>\n",
       "      <td>10.069</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.396</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.237</td>\n",
       "      <td>2.334</td>\n",
       "      <td>2.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>147</td>\n",
       "      <td>62.914</td>\n",
       "      <td>10.321</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.406</td>\n",
       "      <td>1.259</td>\n",
       "      <td>0.289</td>\n",
       "      <td>2.310</td>\n",
       "      <td>2.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>131</td>\n",
       "      <td>66.377</td>\n",
       "      <td>10.337</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.419</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.308</td>\n",
       "      <td>2.270</td>\n",
       "      <td>2.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      No. of Models  Quantity   Price  Domestic  Japan  European  HP/Wt  \\\n",
       "year                                                                      \n",
       "71               92    86.892   7.868     0.866  0.057     0.077  0.490   \n",
       "72               89    98.623   7.979     0.892  0.042     0.066  0.391   \n",
       "73               86    92.785   7.535     0.932  0.040     0.028  0.364   \n",
       "74               72   105.119   7.506     0.887  0.050     0.064  0.347   \n",
       "75               93    84.775   7.821     0.853  0.083     0.064  0.337   \n",
       "76               99    93.382   7.787     0.876  0.081     0.043  0.338   \n",
       "77               95    97.727   7.651     0.837  0.112     0.051  0.340   \n",
       "78               95    99.444   7.645     0.855  0.107     0.039  0.346   \n",
       "79              102    82.742   7.599     0.803  0.158     0.038  0.348   \n",
       "80              103    71.567   7.718     0.773  0.191     0.036  0.350   \n",
       "81              116    62.030   8.349     0.741  0.213     0.046  0.349   \n",
       "82              110    61.893   8.831     0.714  0.235     0.051  0.347   \n",
       "83              115    67.878   8.821     0.734  0.215     0.051  0.351   \n",
       "84              113    85.933   8.870     0.783  0.179     0.038  0.361   \n",
       "85              136    78.143   8.938     0.761  0.191     0.048  0.372   \n",
       "86              130    83.756   9.382     0.733  0.216     0.050  0.379   \n",
       "87              143    67.667   9.965     0.702  0.245     0.052  0.395   \n",
       "88              150    67.078  10.069     0.717  0.237     0.045  0.396   \n",
       "89              147    62.914  10.321     0.690  0.261     0.049  0.406   \n",
       "90              131    66.377  10.337     0.682  0.276     0.043  0.419   \n",
       "\n",
       "       Size    Air    MPG    MP$  \n",
       "year                              \n",
       "71    1.496  0.000  1.662  1.849  \n",
       "72    1.510  0.014  1.619  1.875  \n",
       "73    1.529  0.022  1.589  1.818  \n",
       "74    1.510  0.026  1.567  1.452  \n",
       "75    1.479  0.054  1.584  1.503  \n",
       "76    1.508  0.059  1.759  1.696  \n",
       "77    1.467  0.032  1.947  1.835  \n",
       "78    1.405  0.034  1.982  1.929  \n",
       "79    1.343  0.047  2.061  1.657  \n",
       "80    1.296  0.078  2.215  1.466  \n",
       "81    1.286  0.094  2.363  1.559  \n",
       "82    1.277  0.134  2.440  1.817  \n",
       "83    1.276  0.126  2.601  2.087  \n",
       "84    1.293  0.129  2.469  2.117  \n",
       "85    1.265  0.140  2.261  2.024  \n",
       "86    1.249  0.176  2.416  2.856  \n",
       "87    1.246  0.229  2.327  2.789  \n",
       "88    1.251  0.237  2.334  2.919  \n",
       "89    1.259  0.289  2.310  2.806  \n",
       "90    1.270  0.308  2.270  2.852  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table\n",
    "table_1 = pd.DataFrame()\n",
    "\n",
    "# calculate weighted means of the following column with quantity weights\n",
    "table_1[[\"Price\", \"Domestic\", \"Japan\", \"European\", \"HP/Wt\", \"Size\", \"Air\", \"MPG\", \"MP$\", \"drop\"]] = \\\n",
    "df[[\"price\", \"domestic\", \"japan\", \"european\", \"hpwt\", \"space\", \"air\", \"mpg\", \"mpd\", \"quantity\"]] \\\n",
    "    .groupby(df.year).apply(lambda x: pd.Series(np.average(x, weights=x[\"quantity\"], axis = 0)))\n",
    "\n",
    "# count number of models per year/market\n",
    "table_1.insert(0, \"No. of Models\", df.groupby(\"year\").sum().cons.values)\n",
    "\n",
    "# mean quantity per year/market\n",
    "table_1.insert(1, \"Quantity\", df.quantity.groupby(df.year).mean()) \n",
    "\n",
    "# delete the extraneous weighted quantity column\n",
    "table_1.drop('drop', axis=1, inplace=True)\n",
    "np.round(table_1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2eab5b",
   "metadata": {},
   "source": [
    "#### Table III: Results with Logit Demand and Marginal Cost Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d352c",
   "metadata": {},
   "source": [
    "1. The first column shows the result of the OLS logit demand:\n",
    "\\begin{align}\n",
    "ln(s_j)-ln(s_0) = -\\alpha p_j + x_j'\\beta + \\xi_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb28b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.07300751,  -0.12309488,  -0.03441478,   0.26546568,\n",
       "         2.34191416,  -0.08860627])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_column1 = LinearRegression().fit(df[[\"hpwt\", \"air\", \"mpd\", \"space\", \"price\"]], df.diff_2)\n",
    "np.hstack((table3_column1.intercept_, table3_column1.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3070cc8",
   "metadata": {},
   "source": [
    "2. The second column shows the result of IV logit demand: (we use 2-step GMM for estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "030f177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.27629294,  1.94935115,  1.28739148,  0.05456147,  2.35760254,\n",
       "       -0.21578695])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate IV for demand and supply sides\n",
    "tempDemand = generate_iv(X_d, firms, unique_mkts, markets)\n",
    "tempSupply = generate_iv(X_s, firms, unique_mkts, markets)\n",
    "\n",
    "# generate demand IV matrix Z\n",
    "Z_d = np.hstack((X_d, tempDemand[0], tempDemand[1]))\n",
    "\n",
    "# generate supply IV matrix Z\n",
    "Z_s = np.hstack((X_s, tempSupply[0], tempSupply[1], df.mpd.values.reshape((-1,1))))\n",
    "\n",
    "# generate full characteristic matrix X by including price\n",
    "X_base = np.hstack((X_d, p.reshape((-1,1))))\n",
    "\n",
    "# define matrices\n",
    "ZX = Z_d.T @ X_base\n",
    "ZDelta = Z_d.T @ delta_0\n",
    "\n",
    "# 1st-step GMM using identity weighting matrix\n",
    "first_beta = np.linalg.inv(ZX.T @ ZX) @ ZX.T @ ZDelta\n",
    "\n",
    "# obtain the residual\n",
    "e = delta_0 - X_base @ first_beta\n",
    "\n",
    "# calculate the optimal weighting matrix\n",
    "# which is the inverse of the variance of the moment function\n",
    "moment = e.reshape((-1,1)) * Z_d\n",
    "\n",
    "demean = moment - moment.mean(axis=0).reshape((1,-1))\n",
    "\n",
    "cov = demean.T @ demean / demean.shape[0]\n",
    "\n",
    "W_iv = np.linalg.inv(cov)\n",
    "\n",
    "# 2nd-step GMM using the optimal weighting matrix\n",
    "table3_column2 = np.linalg.inv(ZX.T @ W_iv @ ZX) @ ZX.T @ W_iv @ ZDelta\n",
    "\n",
    "table3_column2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034431d5",
   "metadata": {},
   "source": [
    "3. The third column shows the result of OLS ln(price) on $w$:\n",
    "\\begin{align}\n",
    "ln(p) = w'\\gamma + \\omega\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b87205b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.88192125,  0.52033668,  0.6797513 , -0.47064027,  0.12482708,\n",
       "        0.01283075])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table3_column3 = LinearRegression().fit(\n",
    "    df[[\"ln_hpwt\", \"air\", \"ln_mpg\", \"ln_space\", \"trend\"]], df.ln_price)\n",
    "\n",
    "np.hstack((table3_column3.intercept_, table3_column3.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465d13b",
   "metadata": {},
   "source": [
    "#### Table IV: Esimated Parameters of the Demand and Pricing Equations (column 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2559a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack IV matrice for demand and supply\n",
    "Z = scipy.linalg.block_diag(Z_d, Z_s)\n",
    "\n",
    "# initial weighting matrix suggested by Aviv Nevo's appendix\n",
    "W_init = np.linalg.inv(Z.T @ Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee543c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.666961193084717"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if the objective function works given a set of non-linear starting parameters\n",
    "# this starting parameter is from BLP(1995)\n",
    "theta_2 = [3.612, 4.628, 1.818, 1.050, 2.056, 43.501]\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "obj = obj_fcn(theta_2, df.share.values, \n",
    "              X_d, V, p, y_it, J, T, N, unique_mkts, markets, 1e-5,\n",
    "             Z_d, Z_s, X_s, W_init, firms)\n",
    "\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61cba39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.18846082687378"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st-step GMM estimation:\n",
    "# search over parameters that minimize the objective function using initial weighting matrix\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "# set bounds for parameter space\n",
    "bds = ((0,np.inf), (0,np.inf), (0,np.inf), \n",
    "        (0,np.inf), (0,np.inf), (5,np.inf))\n",
    "\n",
    "first_step_est = minimize(obj_fcn,\n",
    "                          theta_2, \n",
    "                          args = (df.share.values, X_d, V, p, y_it, \n",
    "                                  J, T, N, unique_mkts, markets, 1e-4, \n",
    "                                  Z_d, Z_s, X_s, W_init, firms), \n",
    "                          bounds = bds,\n",
    "                          method = \"L-BFGS-B\",\n",
    "                          options = {'maxiter': 1000, 'maxfun': 1000, 'eps': 1e-3},\n",
    "                          tol = 1e-4)\n",
    "\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74e9f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "outfile = open(\"first_step_est_bfgs.pickle\", \"wb\")\n",
    "pickle.dump(first_step_est, outfile)\n",
    "outfile.close()\n",
    "\n",
    "# Reading\n",
    "with open(\"first_step_est_bfgs.pickle\", \"rb\") as infile:\n",
    "    first_step_est = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95f1d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the (feasible) optimal weighting matrix\n",
    "first_theta_2 = first_step_est.x\n",
    "\n",
    "# calculate mean utility given the optimal parameters\n",
    "d.delta = solve_delta(df.share.values, X_d, V, p, y_it,\n",
    "                         d.delta, first_theta_2, J, T, N, 1e-5)\n",
    "\n",
    "# calculate probabilities and shares given the optimal theta_2\n",
    "q_s = compute_share(X_d, V, p, y_it, d.delta, first_theta_2, J, T, N)\n",
    "\n",
    "# calculate marginal costs\n",
    "mc = compute_mc(q_s, firms, p, y_it, first_theta_2[5], J, T, N, unique_mkts, markets).reshape((-1,1))\n",
    "\n",
    "# stack matrices for regression\n",
    "y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))\n",
    "X = scipy.linalg.block_diag(X_d,X_s)\n",
    "Z = scipy.linalg.block_diag(Z_d,Z_s)\n",
    "\n",
    "# obtain the error\n",
    "first_theta_1 = np.linalg.inv(X.T @ Z @ W_init @ Z.T @ X) @ (X.T @ Z @ W_init @ Z.T @ y2)\n",
    "xi_w = y2 - X @ first_theta_1\n",
    "\n",
    "# calculate weighting matrix\n",
    "moment_blp = Z * xi_w\n",
    "cov_blp = moment_blp.T @ moment_blp / np.sum(J)\n",
    "\n",
    "optimal_weight = scipy.linalg.inv(cov_blp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f9fc9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.58367586135864"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now search for optimal parameters with the optimal weighting matrix\n",
    "t2 = time.time()\n",
    "\n",
    "second_step_est = minimize(obj_fcn,\n",
    "                          theta_2, \n",
    "                          args = (df.share.values, X_d, V, p, y_it, \n",
    "                                  J, T, N, unique_mkts, markets, 1e-4, \n",
    "                                  Z_d, Z_s, X_s, optimal_weight, firms), \n",
    "                          bounds = bds,\n",
    "                          method = \"L-BFGS-B\",\n",
    "                          options = {'maxiter': 1000, 'maxfun': 1000, 'eps': 1e-3},\n",
    "                          tol = 1e-4)\n",
    "\n",
    "time.time() - t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3251f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "outfile = open(\"second_step_est.pickle\", \"wb\")\n",
    "pickle.dump(second_step_est, outfile)\n",
    "outfile.close()\n",
    "\n",
    "# Reading\n",
    "with open(\"second_step_est.pickle\", \"rb\") as infile:\n",
    "    second_step_est = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9131a",
   "metadata": {},
   "source": [
    "1. Non-linear parameter estimates: Std. Deviations ($\\sigma_\\beta$'s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ee6df47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.6119995 ,  4.6278806 ,  1.8179531 ,  1.04997291,  2.05594696,\n",
       "       43.5000067 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_theta_2 = second_step_est.x\n",
    "second_theta_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8cc33",
   "metadata": {},
   "source": [
    "2. Linear parameters:\n",
    "\n",
    "First 5 are the demand side means (Constant, HP/Weight, Air, MP$, Size)\n",
    "\n",
    "Last 6 are the cost side params (Constant, ln(HP/Weight), Air, ln(MPG), ln(Size), Trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c69f7a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.49341121],\n",
       "       [ 2.67870538],\n",
       "       [ 0.68947476],\n",
       "       [ 0.07518924],\n",
       "       [ 3.97380871],\n",
       "       [ 1.32364628],\n",
       "       [ 0.50838294],\n",
       "       [ 0.59417088],\n",
       "       [-0.34508292],\n",
       "       [-0.07242206],\n",
       "       [ 0.01432692]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.delta = solve_delta(df.share.values, X_d, V, p, y_it, d.delta, second_theta_2,\n",
    "                        J, T, N, 1e-4)\n",
    "q_s = compute_share(X_d, V, p, y_it, d.delta, second_theta_2, J, T, N)\n",
    "\n",
    "mc = compute_mc(q_s, firms, p, y_it, second_theta_2[5], J, T, N, unique_mkts, markets).reshape((-1,1))\n",
    "\n",
    "y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))\n",
    "\n",
    "second_theta_1 = np.linalg.inv(X.T @ Z @ optimal_weight @ Z.T @ X) @ (X.T @ Z @ optimal_weight @ Z.T @ y2)\n",
    "second_theta_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58d0a2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30665511092130693"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average markup (compare to table 12 of Conlon and Gortmaker (2019))\n",
    "np.mean((p.flatten() - mc.flatten()) / p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de895ca2",
   "metadata": {},
   "source": [
    "#### Table VI: Own- and Cross-Price Semi-Elasticities:\n",
    "\n",
    "(the change of percentage market share given the  \\$1k price change)\n",
    "\n",
    "$\\epsilon_{ij} = \\frac{\\partial s_i}{\\partial p_j} \\cdot \\frac{100}{s_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19da3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first compute the Omega matrix (gradient w.r.t. price) using estimates from 2-step GMM\n",
    "# math derivation see above function compute_mc()\n",
    "\n",
    "share_deriv = []\n",
    "q = q_s[0]\n",
    "s = q_s[1]\n",
    "\n",
    "for m in unique_mkts:\n",
    "    # list of firms in that market/year\n",
    "    firm_yr = firms[markets == m]\n",
    "    \n",
    "    # list of prices in that market/year\n",
    "    price = p[markets == m]\n",
    "    \n",
    "    # ownership matrix\n",
    "    ownership = np.equal(firm_yr, np.transpose(firm_yr))\n",
    "    \n",
    "    # individual shares (or individual quantities) for all products in that market/year\n",
    "    q_m = q[markets == m, :]\n",
    "    \n",
    "    # number of products in that market\n",
    "    no_of_products = np.size(q_m, 0)\n",
    "    \n",
    "    # predefine the omega matrix       \n",
    "    deriv_m = np.zeros((no_of_products, no_of_products))\n",
    "    \n",
    "    # calculate omega matrix\n",
    "    for i in range(N):\n",
    "        q_mi = q_m[:, i].reshape((-1,1))\n",
    "        deriv_m += second_theta_2[5] / y_it[i, m - 1] * 1/N * (q_mi @ q_mi.T - np.diag(q_m[:,i]))\n",
    "        \n",
    "    share_deriv.append(deriv_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b684ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00030612])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example, we obtain the own-price derivative for Mazda323 in 1990\n",
    "mz323_deriv = (share_deriv[19][df.modelvec[markets == 20] == \"MZ323\"]).flatten()[df.modelvec[markets == 20] == \"MZ323\"]\n",
    "mz323_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75b0f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.38248361e-06])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or for BMW735i in 1990\n",
    "bw735i_deriv = (share_deriv[19][df.modelvec[markets == 20] == \"BW735i\"]).flatten()[df.modelvec[markets == 20] == \"BW735i\"]\n",
    "bw735i_deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "050a410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the Mazda323 mkt share in 1990\n",
    "mz323_s = s[(markets == 20) & (df.modelvec == \"MZ323\")]\n",
    "\n",
    "# obtain the BMW735i market share in 1990\n",
    "bw735i_s = s[(markets == 20) & (df.modelvec == \"BW735i\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48e25dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-125.36914283])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with table VI, first row first column of BLP (1995)\n",
    "mz323_deriv/ mz323_s * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6110fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create all of table VI\n",
    "\n",
    "# extract all of the cars\n",
    "table_vi_cars = [\"MZ323\", \"NISENT\", \"FDESCO\", \"CVCAVA\", \"HDACCO\", \"FDTAUR\", \"BKCENT\",\n",
    "                \"NIMAXI\", \"ACLEGE\", \"LNTOWN\", \"CDSEVI\", \"LXLS40\", \"BW735i\"]\n",
    "\n",
    "# obtain share derivs and shares relevant cars in 1990\n",
    "deriv_1990 = share_deriv[19]\n",
    "s_1990 = s[markets == 20]\n",
    "\n",
    "# initialize the matrix dimensions of table VI\n",
    "table_vi = np.zeros((len(table_vi_cars), len(table_vi_cars)))\n",
    "\n",
    "# iterate across cars to obtain table VI\n",
    "row = 0\n",
    "for car1 in table_vi_cars:\n",
    "    col = 0\n",
    "    for car2 in table_vi_cars:\n",
    "        table_vi[row, col] = (deriv_1990[df.modelvec[markets == 20] == car1].flatten()[df.modelvec[markets == 20] == car2] /\\\n",
    "                             s_1990[df.modelvec[markets == 20] == car2] *100)\n",
    "        col += 1\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3c426b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MZ323</th>\n",
       "      <th>NISENT</th>\n",
       "      <th>FDESCO</th>\n",
       "      <th>CVCAVA</th>\n",
       "      <th>HDACCO</th>\n",
       "      <th>FDTAUR</th>\n",
       "      <th>BKCENT</th>\n",
       "      <th>NIMAXI</th>\n",
       "      <th>ACLEGE</th>\n",
       "      <th>LNTOWN</th>\n",
       "      <th>CDSEVI</th>\n",
       "      <th>LXLS40</th>\n",
       "      <th>BW735i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MZ323</th>\n",
       "      <td>-125.369</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISENT</th>\n",
       "      <td>1.936</td>\n",
       "      <td>-107.754</td>\n",
       "      <td>1.625</td>\n",
       "      <td>1.393</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDESCO</th>\n",
       "      <td>12.031</td>\n",
       "      <td>9.475</td>\n",
       "      <td>-98.553</td>\n",
       "      <td>7.843</td>\n",
       "      <td>1.650</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVCAVA</th>\n",
       "      <td>10.299</td>\n",
       "      <td>8.302</td>\n",
       "      <td>8.017</td>\n",
       "      <td>-101.361</td>\n",
       "      <td>1.926</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDACCO</th>\n",
       "      <td>2.085</td>\n",
       "      <td>2.488</td>\n",
       "      <td>2.384</td>\n",
       "      <td>2.723</td>\n",
       "      <td>-47.253</td>\n",
       "      <td>1.953</td>\n",
       "      <td>1.530</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDTAUR</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1.172</td>\n",
       "      <td>1.467</td>\n",
       "      <td>-40.411</td>\n",
       "      <td>1.057</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BKCENT</th>\n",
       "      <td>0.285</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.378</td>\n",
       "      <td>-42.275</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIMAXI</th>\n",
       "      <td>0.049</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.675</td>\n",
       "      <td>-27.509</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACLEGE</th>\n",
       "      <td>0.007</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.221</td>\n",
       "      <td>-15.244</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNTOWN</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-13.311</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDSEVI</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-10.714</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LXLS40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.160</td>\n",
       "      <td>-9.024</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BW735i</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-5.744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MZ323   NISENT  FDESCO   CVCAVA  HDACCO  FDTAUR  BKCENT  NIMAXI  \\\n",
       "MZ323  -125.369    0.900   0.959    0.803   0.115   0.052   0.059   0.011   \n",
       "NISENT    1.936 -107.754   1.625    1.393   0.295   0.135   0.147   0.036   \n",
       "FDESCO   12.031    9.475 -98.553    7.843   1.650   0.644   0.766   0.180   \n",
       "CVCAVA   10.299    8.302   8.017 -101.361   1.926   1.104   0.977   0.264   \n",
       "HDACCO    2.085    2.488   2.384    2.723 -47.253   1.953   1.530   0.988   \n",
       "FDTAUR    0.706    0.852   0.699    1.172   1.467 -40.411   1.057   0.651   \n",
       "BKCENT    0.285    0.333   0.298    0.372   0.411   0.378 -42.275   0.757   \n",
       "NIMAXI    0.049    0.072   0.062    0.090   0.237   0.208   0.675 -27.509   \n",
       "ACLEGE    0.007    0.011   0.010    0.013   0.059   0.063   0.156   0.221   \n",
       "LNTOWN    0.008    0.014   0.012    0.019   0.101   0.195   0.336   0.443   \n",
       "CDSEVI    0.001    0.002   0.002    0.003   0.019   0.028   0.048   0.091   \n",
       "LXLS40    0.002    0.003   0.003    0.003   0.022   0.021   0.049   0.108   \n",
       "BW735i    0.000    0.000   0.000    0.000   0.002   0.003   0.006   0.014   \n",
       "\n",
       "        ACLEGE  LNTOWN  CDSEVI  LXLS40  BW735i  \n",
       "MZ323    0.003   0.001   0.001   0.001   0.000  \n",
       "NISENT   0.010   0.005   0.003   0.004   0.001  \n",
       "FDESCO   0.055   0.024   0.017   0.021   0.004  \n",
       "CVCAVA   0.070   0.038   0.026   0.023   0.007  \n",
       "HDACCO   0.459   0.282   0.234   0.228   0.078  \n",
       "FDTAUR   0.369   0.411   0.263   0.161   0.103  \n",
       "BKCENT   0.326   0.253   0.164   0.135   0.059  \n",
       "NIMAXI   0.413   0.298   0.275   0.264   0.135  \n",
       "ACLEGE -15.244   0.184   0.196   0.197   0.137  \n",
       "LNTOWN   0.509 -13.311   0.528   0.422   0.334  \n",
       "CDSEVI   0.121   0.118 -10.714   0.129   0.115  \n",
       "LXLS40   0.151   0.117   0.160  -9.024   0.158  \n",
       "BW735i   0.027   0.023   0.036   0.040  -5.744  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store in dataframe for easier viewing\n",
    "table_vi = pd.DataFrame(np.round(table_vi, 3))\n",
    "\n",
    "# renaming rows and columns\n",
    "table_vi.index = table_vi_cars\n",
    "table_vi.columns = table_vi_cars\n",
    "\n",
    "table_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7cfbeb",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "Berry, S., Levinsohn, J., & Pakes, A. (1995). Automobile prices in market equilibrium. Econometrica: Journal of the Econometric Society, 841-890.\n",
    "\n",
    "Nevo, A. (2000). A practitioner's guide to estimation of randomâ€coefficients logit models of demand. Journal of economics & management strategy, 9(4), 513-548.\n",
    "\n",
    "Ivan Li's website: Replication of the classic BLP (1995). Retrieved June, 2023, from https://www.ivan-li.com/code/blp_1995"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
