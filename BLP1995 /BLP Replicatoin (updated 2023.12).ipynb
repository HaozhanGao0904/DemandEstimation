{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d436c465",
   "metadata": {},
   "source": [
    "# A Replication of BLP(1995)\n",
    "##### Last update: Dec. 2023\n",
    "\n",
    "### This file replicates the following results in BLP(1995):\n",
    "\n",
    "* Table I: Descriptive Statistics\n",
    "* Table III: Results with Logit Demand and Marginal Cost Pricing\n",
    "* Table IV: Esimated Parameters of the Demand and Pricing Equations (column 3)\n",
    "* Table VI: A Sample of Estimated Own- and Cross-Price Semi-Elasticities\n",
    "\n",
    "### Content:\n",
    "\n",
    "1. [The Model](#1.-The-Model)\n",
    "1. [Estimation Procedure](#2.-Estimation-Procedure)\n",
    "1. [Define Functions](#3.-Define-Functions)\n",
    "1. [Replications](#4.-Replications)\n",
    "1. [Citations](#Citations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cfacc",
   "metadata": {},
   "source": [
    "## 1. The Model ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79833c64",
   "metadata": {},
   "source": [
    "### Demand Side:\n",
    "Suppose there are $T$ markets (each market is a year), and $J_t$ products in each market $t$.\n",
    "\n",
    "For each consumer $i$, his utility for purchasing product $j$ in market $t$ is given by:\n",
    "\n",
    "$$\n",
    "u_{ijt} = \\alpha log(y_i-p_j) + x_{jt}'\\beta_i + \\xi_{jt} + \\epsilon_{ijt}\n",
    "$$\n",
    "\n",
    "where $y_i$ is his income, $p_j$ is price, $x_{jt}$ is a vector of observable product characteristics, $\\xi_{jt}$ is the unobservable average utility from consuming product $j$ in the population, and $\\epsilon_{ijt}$ is the idiosyncratic error term. \n",
    "\n",
    "Note that, the coefficient $\\beta_i$ is individual-specific. We may interested in the \"average taste\" for the total population. Hence, we decompose it into two parts and rewrite our utility representation:\n",
    "\n",
    "\\begin{align}\n",
    "u_{ijt} &= \\alpha log(y_i-p_j) + x_{jt}'\\bar\\beta + \\sum_k\\sigma_kx_{jk}v_{ik} + \\xi_{jt} +  \\epsilon_{ijk} \\\\\n",
    "        &= \\alpha log(y_i-p_j) + \\delta_{jt} +  \\sum_k\\sigma_kx_{jk}v_{ik} +  \\epsilon_{ijk}\n",
    "\\end{align}\n",
    "\n",
    "where $\\delta_{jt} =x_{jt}'\\bar\\beta + \\xi_{jt}  $ is the mean utility, $(\\zeta_i,\\epsilon_i) = (v_{i1},...v_{ik};\\epsilon_{i0},...\\epsilon_{iJ})$ are random variables with mean zero. In this practice, we assume $\\zeta_i$ is standard normal and $\\epsilon_i$ is T1EV.\n",
    "\n",
    "One caveat is that, when $y_i<p_i$, e.g. a worker's income is less than the price of an expensive car, this will cause a problem. Therefore, we modify the utiliy function as:\n",
    "\n",
    "\\begin{align}\n",
    "u_{ijt} &= \\delta_{jt} +  \\sum_k\\sigma_kx_{jk}v_{ik} +  \\epsilon_{ijk} -\\alpha \\frac{p_{jt}}{y_i}\n",
    "\\end{align}\n",
    "\n",
    "For the outside good (not buying):\n",
    "\\begin{align}\n",
    "    u_{i0t} = \\alpha log(y_i) + \\xi_0 + \\sigma_0v_{i0} + \\epsilon_{io},  \\forall t \\in T\n",
    "\\end{align}\n",
    "\n",
    "The mean utility of outside good is normalized to 0 for simplicity.\n",
    "\n",
    "The parameters of interest $\\theta = \\{\\theta_1, \\theta_2\\}$ has two parts: Ones that for population $\\theta_1 = \\bar\\beta$ (since it can be estimated in a linear form, it is called \"linear parameters\"), and ones for idiosyncratic variances $\\theta_2 = \\{\\alpha; \\sigma_1,...\\sigma_k\\}$ (we call them \"nonlinear parameters\").\n",
    "\n",
    "\n",
    "Since $\\epsilon$ is T1EV and each consumer can only buy one good, the predicted market share is then given by a mixed logit form:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat s_{jt} &= \\int\\mathbb1\\{u_{ijt}\\geq u_{ikt}, \\forall k\\neq j\\}dF(y_i, \\zeta_i) \\\\\n",
    "       &= \\int \\frac{exp\\{\\alpha log(y_i-p_j) + \\delta_{jt} + \\sum_k\\sigma_kx_{jk}v_{ik} \\} }{1 + \\sum_{l=1}^Jexp\\{\\alpha log(y_i-p_l) + \\delta_{lt} + \\sum_k\\sigma_kx_{lk}v_{ik} \\}}dF(y_i, \\zeta_i)\\\\\n",
    "       &= \\sum_{i=1}^{N}\\frac{exp\\{\\alpha log(y_i-p_j) + \\delta_{jt} + \\sum_k\\sigma_kx_{jk}v_{ik} \\} }{1 + \\sum_{l=1}^Jexp\\{\\alpha log(y_i-p_l) + \\delta_{lt} + \\sum_k\\sigma_kx_{lk}v_{ik} \\}}\n",
    "\\end{align}\n",
    "\n",
    "where N is the number of simulation draws in each market.\n",
    "\n",
    "Actually, real market share $s_{jt}$ is observable and we should let our predicted share equalize the real share $\\hat s_{jt} = s_{jt}$.\n",
    "\n",
    "\n",
    "Note that, $\\hat s_{jt}(\\delta_{jt})$ is a function of $\\delta_{jt}$, and we can invert it to obtain a constraction mapping (which is proved by BLP(1995)):\n",
    "\n",
    "\\begin{align}\n",
    "\\delta_{jt}^{h+1} = \\delta_{jt}^h + ln(s_{jt}) - ln(\\hat s_{jt}(\\delta_{jt}^h))\n",
    "\\end{align}\n",
    "\n",
    "Hence, given nonlinear parameters $\\theta$, we can obtain the mean utility $\\delta$, which furthermore implies a linear equation  $\\delta_{jt} =x_{jt}'\\bar\\beta + \\xi_{jt}  $. We can run regression to obtain the linear parameters $\\bar\\beta$.\n",
    "\n",
    "However, $\\mathbb E[\\xi_{jt}|x_{jt}] \\neq 0$ brings the endogeneity problem. We use characterstics of other goods in the same market as instruments $Z_{d}$ suggested by BLP(1995)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e852428",
   "metadata": {},
   "source": [
    "### Supply Side:\n",
    "\n",
    "We assume there are $F$ firms, each of which product a subset $\\mathcal J_f$ of the $J$ goods. The cost characteristics are decomposed into a subset which is observed by econometrician $w_j$, and an unobserved component $\\omega_j$. Note that $x_j$ for consumers may be part of $w_j$, and $\\omega_j$ is correlated with $\\xi_j$. \n",
    "\n",
    "We assume the marginal cost of good $j$ can be written as:\n",
    "\\begin{align}\n",
    "ln(mc_j) = w_j\\gamma+\\omega_j\n",
    "\\end{align}\n",
    "where $\\gamma$ is a vector of parameters to be estimated.\n",
    "\n",
    "The profit of firm $f$ is given by:\n",
    "\\begin{align}\n",
    "\\Pi_f = \\sum_{j\\in\\mathcal J_f} (p_j-mc_j)\\cdot Ms_j(p,x,\\xi,\\theta)\n",
    "\\end{align}\n",
    "\n",
    "where $M$ is the total number of consumers at a given market.\n",
    "\n",
    "Our FOC is then\n",
    "\\begin{align}\n",
    "s_j + \\sum_{r\\in\\mathcal J_f}(p_r-mc_r)\\frac{\\partial s_r}{\\partial p_j} = 0, \\forall j\\in\\mathcal J_f\n",
    "\\end{align}\n",
    "\n",
    "This implies the price-cost markups $b(p,x,\\xi,\\theta) = p-mc$ can be expressed as:\n",
    "\\begin{align}\n",
    "b(p,x,\\xi,\\theta) = \\Omega^{-1}s(p,x,\\xi,\\theta)\n",
    "\\end{align}\n",
    "\n",
    "where $\\Omega_{jr} = -\\frac{\\partial s_r}{\\partial p_j}$ if $r$ and $j$ are produced by the same firm and $\\Omega_{jr} = 0$ otherwise.\n",
    "\n",
    "Hence, we have the regression equation as\n",
    "\n",
    "\\begin{align}\n",
    "ln(p-b(p,x,\\xi,\\theta) ) = w\\gamma+\\omega\n",
    "\\end{align}\n",
    "\n",
    "Notice that, we still need to instrumenting for $w$ since cost characteristics may be correlated to unobserved disturbance. BLP uses all other products' characteristics as instrument $Z_s$ since products that face good substitudes will tend to have lower markups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e928dc",
   "metadata": {},
   "source": [
    "## 2. Estimation Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43a8e8",
   "metadata": {},
   "source": [
    "We do the estimation using **Nested Fixed Point Algorithm**:\n",
    "\n",
    "Outer loop: Search over nonlinear parameters $\\theta_2$\n",
    "\n",
    "Inner loop: for given $\\theta_2$:\n",
    "* Use contraction mapping to find mean utilities $\\hat\\delta$ given market share $s$\n",
    "* Use $\\hat\\delta$ and the demand instrument $Z_d$ to find linear paramters $\\hat\\theta_1$ and residual $\\hat\\xi$\n",
    "* Compute markup $b(\\theta)$, use it and the supply instrument $Z_s$ to run IV regression to find $\\hat\\omega$\n",
    "* Form the GMM objective function of $\\hat \\theta = \\text{argmin}_{\\theta\\in\\Theta} Z'\\hat {G}'W\\hat GZ$, where $Z = (Z'_d, Z'_s)'$ and $\\hat G = (\\hat{\\xi}', \\hat{\\omega}')'$, since IVs are orthogonal to error terms.\n",
    "\n",
    "Note that, we need to conduct 2-step GMM since we need to obtain the optimal weighting matrix from the first step. \n",
    "\n",
    "The inital weighting matrix is set to $W_0 = ZZ'$ following the suggestion in appendix of Nevo's practitioners' guide.\n",
    "\n",
    "The (feasible) optimal weighting matrix is $\\tilde W = Z'\\hat {G}'\\hat GZ$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3584ab4",
   "metadata": {},
   "source": [
    "## 3. Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a8fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from scipy.optimize import minimize\n",
    "from numba import jit, njit, prange\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02009f74",
   "metadata": {},
   "source": [
    "The following cells is for data cleaning and create necessary variables for estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fcc1040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelvec</th>\n",
       "      <th>newmodv</th>\n",
       "      <th>model_year</th>\n",
       "      <th>id</th>\n",
       "      <th>firmid</th>\n",
       "      <th>market</th>\n",
       "      <th>hpwt</th>\n",
       "      <th>space</th>\n",
       "      <th>air</th>\n",
       "      <th>mpd</th>\n",
       "      <th>...</th>\n",
       "      <th>ln_space</th>\n",
       "      <th>ln_mpg</th>\n",
       "      <th>ln_mpd</th>\n",
       "      <th>ln_price</th>\n",
       "      <th>trend</th>\n",
       "      <th>cons</th>\n",
       "      <th>s_0</th>\n",
       "      <th>s_i</th>\n",
       "      <th>diff</th>\n",
       "      <th>diff_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMGREM</td>\n",
       "      <td>AMGREM71</td>\n",
       "      <td>71</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528997</td>\n",
       "      <td>1.1502</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139936</td>\n",
       "      <td>0.528862</td>\n",
       "      <td>0.635595</td>\n",
       "      <td>1.596515</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171483</td>\n",
       "      <td>-6.858013</td>\n",
       "      <td>-6.686531</td>\n",
       "      <td>-6.730300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMHORN</td>\n",
       "      <td>AMHORN71</td>\n",
       "      <td>71</td>\n",
       "      <td>130</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.494324</td>\n",
       "      <td>1.2780</td>\n",
       "      <td>0</td>\n",
       "      <td>1.935989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245296</td>\n",
       "      <td>0.553885</td>\n",
       "      <td>0.660618</td>\n",
       "      <td>1.707662</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171483</td>\n",
       "      <td>-7.308233</td>\n",
       "      <td>-7.136750</td>\n",
       "      <td>-7.180520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMJAVL</td>\n",
       "      <td>AMJAVL71</td>\n",
       "      <td>71</td>\n",
       "      <td>132</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467613</td>\n",
       "      <td>1.4592</td>\n",
       "      <td>0</td>\n",
       "      <td>1.716799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377888</td>\n",
       "      <td>0.433729</td>\n",
       "      <td>0.540462</td>\n",
       "      <td>1.961311</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171483</td>\n",
       "      <td>-7.983628</td>\n",
       "      <td>-7.812146</td>\n",
       "      <td>-7.855915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMMATA</td>\n",
       "      <td>AMMATA71</td>\n",
       "      <td>71</td>\n",
       "      <td>134</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426540</td>\n",
       "      <td>1.6068</td>\n",
       "      <td>0</td>\n",
       "      <td>1.687871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474245</td>\n",
       "      <td>0.416735</td>\n",
       "      <td>0.523468</td>\n",
       "      <td>1.922716</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171483</td>\n",
       "      <td>-7.557843</td>\n",
       "      <td>-7.386360</td>\n",
       "      <td>-7.430130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAMBS</td>\n",
       "      <td>AMAMBS71</td>\n",
       "      <td>71</td>\n",
       "      <td>136</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452489</td>\n",
       "      <td>1.6458</td>\n",
       "      <td>0</td>\n",
       "      <td>1.504286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498227</td>\n",
       "      <td>0.301585</td>\n",
       "      <td>0.408318</td>\n",
       "      <td>2.189237</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.171483</td>\n",
       "      <td>-7.724201</td>\n",
       "      <td>-7.552718</td>\n",
       "      <td>-7.596488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  modelvec   newmodv  model_year   id  firmid  market      hpwt   space  air  \\\n",
       "0   AMGREM  AMGREM71          71  129      15       1  0.528997  1.1502    0   \n",
       "1   AMHORN  AMHORN71          71  130      15       1  0.494324  1.2780    0   \n",
       "2   AMJAVL  AMJAVL71          71  132      15       1  0.467613  1.4592    0   \n",
       "3   AMMATA  AMMATA71          71  134      15       1  0.426540  1.6068    0   \n",
       "4   AMAMBS  AMAMBS71          71  136      15       1  0.452489  1.6458    0   \n",
       "\n",
       "        mpd  ...  ln_space    ln_mpg    ln_mpd  ln_price  trend  cons  \\\n",
       "0  1.888146  ...  0.139936  0.528862  0.635595  1.596515     71     1   \n",
       "1  1.935989  ...  0.245296  0.553885  0.660618  1.707662     71     1   \n",
       "2  1.716799  ...  0.377888  0.433729  0.540462  1.961311     71     1   \n",
       "3  1.687871  ...  0.474245  0.416735  0.523468  1.922716     71     1   \n",
       "4  1.504286  ...  0.498227  0.301585  0.408318  2.189237     71     1   \n",
       "\n",
       "        s_0       s_i      diff    diff_2  \n",
       "0 -0.171483 -6.858013 -6.686531 -6.730300  \n",
       "1 -0.171483 -7.308233 -7.136750 -7.180520  \n",
       "2 -0.171483 -7.983628 -7.812146 -7.855915  \n",
       "3 -0.171483 -7.557843 -7.386360 -7.430130  \n",
       "4 -0.171483 -7.724201 -7.552718 -7.596488  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataframe\n",
    "df = pd.read_csv(\"blp_1995_data.csv\")\n",
    "df = df.drop(df.columns[0], axis = 1)\n",
    "\n",
    "# create ln of characteristics for supply variables\n",
    "df[[\"ln_hpwt\", \"ln_space\", \"ln_mpg\", \"ln_mpd\", \"ln_price\"]] = \\\n",
    "df[[\"hpwt\", \"space\", \"mpg\", \"mpd\", \"price\"]].apply(lambda x: np.log(x))\n",
    "\n",
    "df[\"trend\"] = df.market.map(lambda x: x + 70) # now trend == year\n",
    "\n",
    "df[\"cons\"] = 1\n",
    "\n",
    "df[\"s_0\"] = np.log(1 - df.share.groupby(df[\"model_year\"]).transform(\"sum\"))\n",
    "\n",
    "df[\"s_i\"] = np.log(df.share)\n",
    "df[\"diff\"] = df.s_i - df.s_0\n",
    "df[\"diff_2\"] = np.log(df.share) - np.log(df.share_out)\n",
    "df[\"ln_price\"] = np.log(df.price)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ee762",
   "metadata": {},
   "source": [
    "For demand side, product characteristics X includes HP/Weight, air, MP$, space and a constant.\n",
    "\n",
    "For supply side, cost characteristics W includes ln(HP/Weight), ln(MPG), ln(space), air, trend and a constant.\n",
    "\n",
    "Also, we obtain income means for 20 markets (years) and a standard deviation of income from CPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84bc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for demand side\n",
    "X = df[[\"cons\", \"hpwt\", \"air\", \"mpd\", \"space\"]].values\n",
    "\n",
    "# variables for supply side\n",
    "W = df[[\"cons\", \"ln_hpwt\", \"air\", \"ln_mpg\", \"ln_space\", \"trend\"]].values\n",
    "\n",
    "# price\n",
    "p = df.price.values\n",
    "\n",
    "# number of goods per market\n",
    "J = df.groupby(\"year\").sum().cons.values\n",
    "\n",
    "# number of draws per market\n",
    "N = 500\n",
    "\n",
    "# number of markets\n",
    "T = len(J)\n",
    "\n",
    "# Estimated log income means and standard deviation for years 1971 - 1990 (from CPS)\n",
    "incomeMeans = [2.01156, 2.06526, 2.07843, 2.05775, 2.02915, 2.05346, 2.06745,\n",
    "               2.09805, 2.10404, 2.07208, 2.06019, 2.06561, 2.07672, 2.10437, 2.12608, 2.16426,\n",
    "               2.18071, 2.18856, 2.21250, 2.18377]\n",
    "sigma_v = 1.72\n",
    "\n",
    "# number of terms that have the random coefficient\n",
    "#  according to table 4, this is constant, hp/wt, air, mp$, size, price\n",
    "k = 5\n",
    "\n",
    "# markets for itj\n",
    "markets = df.market.values\n",
    "\n",
    "# unique markets\n",
    "unique_mkts = np.unique(df.market)\n",
    "\n",
    "# firms\n",
    "firms = np.reshape(df.firmid.values, (-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95fc26",
   "metadata": {},
   "source": [
    "I. Simulate $N$ individuals' income $y_{i}$ for each market $t$. \n",
    "\n",
    "We assume $y_i$ is log-normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40bc0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(66)\n",
    "\n",
    "m_t = np.repeat(incomeMeans, N)\n",
    "\n",
    "# matrix of simulated values\n",
    "#  number of rows = number of simulations\n",
    "#  treat last column is price/income\n",
    "# note that BLP treat it as the same individuals in the market across all years (Nevo 2000)\n",
    "\n",
    "# different draws for each market\n",
    "V = np.reshape(np.random.standard_normal((k + 1) * N * T), (T * N, k + 1))\n",
    "\n",
    "\n",
    "# income if we have different draws per market\n",
    "y_it = np.exp(m_t + sigma_v * V[:, k]).reshape(T,N).T\n",
    "\n",
    "# draws for income if same draws in every market\n",
    "# y_it = np.exp(m_t + sigma_v * np.tile(V[:, k], len(incomeMeans))).reshape(T,N).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23758be1",
   "metadata": {},
   "source": [
    "II. Define a function to compute the predicted markets share $\\hat s_{jt}$ given required data and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950fc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loops that calculate utility in a separate function so that it can be\n",
    "#  run in parallel. \n",
    "@jit\n",
    "def util_iter(out, x, v, p, y, delta, theta_2, J, T, N):\n",
    "    # first iterate over the individuals \n",
    "    for i in prange(N):\n",
    "        # iterator through t and j\n",
    "        tj = 0\n",
    "        \n",
    "        # iterate over the markets\n",
    "        for t in prange(T):\n",
    "            # market size of market t\n",
    "            mktSize = J[t]\n",
    "            \n",
    "            # income for individual i in market t\n",
    "            y_im = y[i, t]\n",
    "            \n",
    "            # iterate over goods in a particular market\n",
    "            for j in prange(mktSize):\n",
    "                out[tj, i] = delta[tj] + \\\n",
    "                v[N * t + i, 0] * theta_2[0] * x[tj, 0] + \\\n",
    "                v[N * t + i, 1] * theta_2[1] * x[tj, 1] + \\\n",
    "                v[N * t + i, 2] * theta_2[2] * x[tj, 2] + \\\n",
    "                v[N * t + i, 3] * theta_2[3] * x[tj, 3] + \\\n",
    "                v[N * t + i, 4] * theta_2[4] * x[tj, 4] - \\\n",
    "                theta_2[5] / y_im * p[tj]\n",
    "                \n",
    "                tj += 1\n",
    "    return out\n",
    "\n",
    "# computes indirect utility given parameters\n",
    "#  x: matrix of demand characteristics\n",
    "#  v: monte carlo draws of N simulations\n",
    "#  p: price vector\n",
    "#  y: income of individuals\n",
    "#  delta: guess for the mean utility\n",
    "#  theta_2: non-linear params (sigma - can think of as stdev's)\n",
    "#  J: vector of number of goods per market\n",
    "#  T: numer of markets\n",
    "#  N: number of simulations\n",
    "\n",
    "@jit\n",
    "def compute_indirect_utility(x, v, p, y, delta, theta_2, J, T, N):\n",
    "    # make sure theta_2 are positive\n",
    "    theta_2 = np.abs(theta_2)\n",
    "    \n",
    "    # output matrix\n",
    "    out = np.zeros((sum(J), N))\n",
    "    \n",
    "    # call the iteration function to calculate utilities\n",
    "    out = util_iter(out, x, v, p, y, delta, theta_2, J, T, N)\n",
    "     \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5733077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the implied shares of goods in each market given inputs\n",
    "# same inputs as above function\n",
    "\n",
    "@jit\n",
    "def compute_share(x, v, p, y, delta, theta_2, J, T, N):\n",
    "    q = np.zeros((np.sum(J), N))\n",
    "    \n",
    "    # obtain vector of indirect utilities\n",
    "    u = compute_indirect_utility(x, v, p, y, delta, theta_2, J, T, N)\n",
    "    \n",
    "    # exponentiate the utilities\n",
    "    exp_u = np.exp(u)\n",
    "    \n",
    "    # pointer to first good in the market\n",
    "    first_good = 0\n",
    "            \n",
    "    for t in range(T):\n",
    "        # market size of market t\n",
    "        mktSize = J[t]\n",
    "\n",
    "        # calculate the numerator of the share eq\n",
    "        numer = exp_u[first_good:first_good + mktSize,:]\n",
    "\n",
    "        # calculate the denom of the share eq\n",
    "        denom = 1 + numer.sum(axis = 0)    \n",
    "          \n",
    "        # calculate the quantity each indv purchases of each good in each market\n",
    "        q[first_good:first_good + mktSize,:] = numer/denom\n",
    "        \n",
    "        first_good += mktSize\n",
    "    \n",
    "    # to obtain shares, assume that each simulation carries the same weight.\n",
    "    # this averages each row, which is essentially computing the sahres for each\n",
    "    #  good in each market. \n",
    "    s = np.matmul(q, np.repeat(1/N, N))\n",
    "    \n",
    "    return [q,s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca11c6c",
   "metadata": {},
   "source": [
    "III. Define the function that uses contraction mapping to find $\\delta_{jt}$ given $s_{jt}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64ead7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a class so I can repeatedly update the delta value\n",
    "class delta:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "\n",
    "# initialize a delta object using the delta_0 values\n",
    "\n",
    "# initial delta_0 estimate: log(share) - log(share outside good)\n",
    "delta_0 = df.diff_2.values\n",
    "d = delta(delta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2e18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def solve_delta(s, x, v, p, y, delta, theta_2, J, T, N, tol):\n",
    "    # define the tolerance variable\n",
    "    eps = 10\n",
    "    \n",
    "    # renaming delta as delta^r\n",
    "    delta_old = delta\n",
    "    \n",
    "    while eps > tol:\n",
    "        # obtain predicted shares and quantities\n",
    "        q_s = compute_share(x, v, p, y, delta_old, \n",
    "                            theta_2, J, T, N)\n",
    "        \n",
    "        # extract the shares\n",
    "        sigma_jt = q_s[1]\n",
    "        \n",
    "        # step 2: use contraction mapping to find delta\n",
    "        delta_new = delta_old + np.log(s/sigma_jt)\n",
    "        \n",
    "        # update tolerance\n",
    "        eps = np.max(np.abs(delta_new - delta_old))\n",
    "        \n",
    "        delta_old = delta_new.copy()\n",
    "        \n",
    "        return delta_old\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7556db8",
   "metadata": {},
   "source": [
    "IV. Define a function to compute marginal cost:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f514f2d",
   "metadata": {},
   "source": [
    "Recall that, $s_j\\approx \\frac{1}{N}\\sum_{i=1}^N\\frac{exp(\\tilde u_{ij})}{1+\\sum_{k=1}^{J}exp(\\tilde u_{ik})}$, where $\\tilde u_{ij} = \\delta_{j} +  \\sum_k\\sigma_kx_{jk}v_{ik} -\\alpha \\frac{p_{j}}{y_i}$ is the indirect utility net of logit shock.\n",
    "\n",
    "Then $\\frac{\\partial s_{j}}{\\partial p_j} = \\frac{1}{N}\\sum_{i=1}^N\\frac{\\alpha}{y_i}(s_{ij}^2-s_{ij})$ and $\\frac{\\partial s_{j}}{\\partial p_k} = \\frac{1}{N}\\sum_{i=1}^N\\frac{\\alpha}{y_i} s_{ij} s_{ik}$, where $s_{ij}$ is the individual share of consumer $i$ on product $j$.\n",
    "\n",
    "Write in matrix form, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\Omega \\approx \\frac{1}{N}\\sum_{i=1}^N\\frac{\\alpha}{y_i}\\cdot \\mathcal H \\cdot (s_i s_i'-diag(s_i)) \n",
    "\\end{align*}\n",
    "\n",
    "where $\\mathcal H$ is the ownership matrix, and $s_i$ is the indivual share of simulated consumer $i$.\n",
    "\n",
    "After obtaining $\\Omega$, we can compute marginal cost by:\n",
    "\\begin{align*}\n",
    "mc = p-b = p - \\Omega^{-1}s\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2670906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the marginal costs given probabilities and shares\n",
    "#  q_s: output of compute share, a list of probabilities matrix(q) and shares vector(s)\n",
    "#  firms: vector of firms operating in each market (length is JxT)\n",
    "#  marks: vector of unique markets (length T)\n",
    "#  markets: vector indicating observation in which market (length JxT)\n",
    "\n",
    "@jit\n",
    "def calc_mc(q_s, firms, p, y, alpha, J, T, N, unique_mkts, markets):\n",
    "    \n",
    "    # declare output vector\n",
    "    out = np.zeros((np.sum(J)))\n",
    "    \n",
    "    # make sure the value of alpha is positive\n",
    "    alpha = np.abs(alpha)\n",
    "    \n",
    "    # read in quantities\n",
    "    q = q_s[0]\n",
    "    \n",
    "    # read in shares\n",
    "    s = q_s[1].reshape((-1,1))\n",
    "    \n",
    "    # reshape some vectors into column vectors\n",
    "    p = p.reshape((-1,1))\n",
    "    \n",
    "    # iterate over markets\n",
    "    for m in unique_mkts:\n",
    "        # obtain list of firms operating in that market/year\n",
    "        firm_yr = firms[markets == m]\n",
    "        \n",
    "        # obtain list of prices of goods in that market/year\n",
    "        price = p[markets == m]\n",
    "        \n",
    "        # J_t x J_t block matrix of 1's indicating goods belonging to same firm in that market/year\n",
    "        # Also known as the ownership matrix\n",
    "        same_firm = np.equal(firm_yr, np.transpose(firm_yr))\n",
    "        \n",
    "        # obtain matrix of probabilities for all simulations for goods in that \n",
    "        #  market/year\n",
    "        yr = q[markets == m,:]\n",
    "        \n",
    "        # obtain number of goods in that market\n",
    "        nobs = np.size(yr, 0)\n",
    "        \n",
    "        # this is the omega matrix initializing        \n",
    "        grad = np.zeros((nobs, nobs))\n",
    "        \n",
    "        # calculate the omega matix by iterating through all individuals\n",
    "        #  Omega matrix is cross-price deriv element-wise product with ownership matrix\n",
    "        for i in range(N):\n",
    "            yr_i = yr[:, i].reshape((-1, 1))\n",
    "            grad += alpha / y[i, m - 1] * same_firm * 1/N * (yr_i @ yr_i.T - np.diag(yr[:,i]))\n",
    "        \n",
    "        # Omega matrix actually requires negative cross price derivs\n",
    "        subMatrix = -grad\n",
    "        \n",
    "        # now obtain the marginal costs\n",
    "        b = np.linalg.inv(subMatrix) @ s[markets == m]\n",
    "        mc = price - b\n",
    "        mc[mc < 0] = .001\n",
    "        \n",
    "        # update entries in the output vector\n",
    "        out[markets == m] = mc.flatten()\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cd0d9",
   "metadata": {},
   "source": [
    "V. Define a function to generate instruments used by BLP(1995):\n",
    "\n",
    "The instrument has two parts:\n",
    "\n",
    "total_firms contains a vector of all summed product/cost characteristics produced by the same firm.\n",
    "\n",
    "total_mkts contains a vector of all summed product/cost characteristics produced by all firms in the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd62e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate instruments for BLP paper\n",
    "# One can also use packages to generate more \"optimal\" instruments instead, like Hausmann instruments\n",
    "# A source of instruments exists in the Conlon and Gortmaker's pyblp package\n",
    "def gen_iv(inx, firms, marks, markets):\n",
    "    totMarket = np.zeros((np.size(inx, axis = 0), np.size(inx, axis = 1)))\n",
    "    totFirm = np.zeros((np.size(inx, axis = 0), np.size(inx, axis = 1)))\n",
    "    \n",
    "    for m in marks:\n",
    "        sub = inx[markets == m, :]\n",
    "        firminfo = firms[markets == m]\n",
    "        same_firm = np.equal(firminfo, np.transpose(firminfo))\n",
    "        \n",
    "        z_1 = np.zeros((np.size(sub,axis = 0), np.size(sub, axis = 1)))\n",
    "        \n",
    "        for i in range(np.size(sub, axis = 1)):\n",
    "            z_1[:,i] = (sub[:,i].reshape((-1,1)) * same_firm).T.sum(axis = 0)\n",
    "        \n",
    "        totFirm[markets == m,:] = z_1\n",
    "        \n",
    "        z_1 = np.zeros((np.size(sub,axis = 0), np.size(sub, axis = 1)))\n",
    "        \n",
    "        for i in range(np.size(sub, axis = 1)):\n",
    "            z_1[:,i] = (sub[:,i].reshape((-1,1)) * (same_firm + np.logical_not(same_firm))).sum(axis = 0)\n",
    "            \n",
    "        totMarket[markets == m, :] = z_1\n",
    "        \n",
    "    return [totFirm, totMarket]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4806e3f",
   "metadata": {},
   "source": [
    "VI: Define objective function that can search over nonlinear parameters $\\theta_2$:\n",
    "\n",
    "1: Given non-linear paramerters $\\theta_2$, actual market share $s$, solve the optimal $\\hat\\delta$\n",
    "\n",
    "2: Compute log marginal cost $log(mc)$. \n",
    "\n",
    "3: Stack $\\mathbf y = (\\hat\\delta', log(mc)')'$, $X = (X_d', X_s')'$, $Z = (Z_d', Z_s')'$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf43c8a",
   "metadata": {},
   "source": [
    "4: Obtain the linear paramter $\\hat\\theta_1 = (X'ZWZ'X)^{-1}X'ZWZ'Y$ by GMM:\n",
    "\n",
    "  Note that we have $\\mathbb E[z_i(y_i-x_i'\\theta_1)] = 0$\n",
    "  \n",
    "  Then we have the sample analog $\\frac{1}{N}Z'Y-\\frac{1}{N}Z'X\\theta_1 = 0$. However, since $d_z>d_{\\theta_1}$, this is a over-identified linear system, the equality cannot hold. We can estimate $\\theta_1$ using GLS (Generalized Least Squares):\n",
    "  \n",
    "  Denote $\\eta = Z'Y$, $G = Z'X$, the previous equation can be written as $\\eta = G\\theta_1 + u$. The estimates of $\\theta_1$ is $\\hat\\theta_1 = (G'WG)^{-1}G'W\\eta$, which is equivalent to $\\hat\\theta_1 = (X'ZWZ'X)^{-1}X'ZWZ'Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4dba1a",
   "metadata": {},
   "source": [
    "5: obtain the residual $\\hat\\xi = \\mathbf y - X\\hat\\theta_1$\n",
    "\n",
    "6: $\\theta_2 = \\text{argmin}_{\\theta\\in\\Theta}\\hat\\xi'Z W Z'\\hat\\xi$ using $\\mathbb E[Z'\\xi] = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b996b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're looking at the four steps Aviv lists in his appendix, start here\n",
    "# This is the objective function that we optimize the non-linear parameters over\n",
    "def objective(theta_2, s, X, V, p, y, J, T, N, marks, markets, tol, \n",
    "              Z, Z_s, W, weigh, firms):\n",
    "    \n",
    "    obs = np.sum(J)\n",
    "    \n",
    "    # Aviv's step 1 & 2:\n",
    "    d.delta = solve_delta(s, X, V, p, y, d.delta, theta_2, J, T, N, tol)\n",
    "    \n",
    "    # obtain the actual implied quantities and shares from converged delta\n",
    "    q_s = compute_share(X, V, p, y, d.delta, theta_2, J, T, N)\n",
    "    \n",
    "    # calculate marginal costs\n",
    "    mc = calc_mc(q_s, firms, p, y, theta_2[5], J, T, N, marks, markets).reshape((-1,1))\n",
    "    \n",
    "    # since we are using both demand and supply side variables,\n",
    "    #  we want to stack the estimated delta and estimated mc\n",
    "    y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))\n",
    "    \n",
    "    # create characteristics matrix that includes both supply and demand side\n",
    "    #  with demand characteristics on the bottom left and supply on the top right\n",
    "    x = scipy.linalg.block_diag(X,W)\n",
    "    \n",
    "    # create matrix of supply and demand instruments, again with\n",
    "    #  demand instruments on the right and supply on the left (top/down changed)    \n",
    "    z = scipy.linalg.block_diag(Z,Z_s)\n",
    "    \n",
    "    # get linear parameters (this FOC is from Aviv's appendix)\n",
    "    b = np.linalg.inv(x.T @ z @ weigh @ z.T @ x) @ (x.T @ z @ weigh @ z.T @ y2)\n",
    "\n",
    "    # Step 3: get the error term xi (also called omega)\n",
    "    xi_w = y2 - x @ b\n",
    "    \n",
    "    # computeo g_bar in GMM methods\n",
    "    g = z.T @ xi_w\n",
    "    \n",
    "    obj = float( g.T @ weigh @ g)\n",
    "   \n",
    "    #print([theta_2, obj])\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9457f9",
   "metadata": {},
   "source": [
    "### 4. Replications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214ea08",
   "metadata": {},
   "source": [
    "#### Table I: Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4226558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table\n",
    "table_1 = pd.DataFrame()\n",
    "\n",
    "# calculate weighted means of the following column with quantity weights\n",
    "table_1[[\n",
    "    \"P\", \"Dom\", \"Japan\", \"Eu\", \"HP_Wt\", \"Size\", \"Air\", \"MPG\", \"MPD\", \"drop\"\n",
    "   ]] = df[[\"price\", \"domestic\", \"japan\", \n",
    "    \"european\", \"hpwt\", \"space\", \n",
    "    \"air\", \"mpg\", \"mpd\", \"quantity\"]] \\\n",
    "    .groupby(df.year) \\\n",
    "    .apply(lambda x: pd.Series(np.average(x, weights=x[\"quantity\"], axis = 0)))\n",
    "\n",
    "# count number of models per year/market\n",
    "table_1.insert(0, \"num_models\", df.groupby(\"year\").sum().cons.values)\n",
    "\n",
    "# mean quantity per year/market\n",
    "table_1.insert(1, \"Q\", df.quantity.groupby(df.year).mean()) \n",
    "\n",
    "# delete the extraneous weighted quantity column\n",
    "table_1.drop('drop', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d540895d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_models</th>\n",
       "      <th>Q</th>\n",
       "      <th>P</th>\n",
       "      <th>Dom</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Eu</th>\n",
       "      <th>HP_Wt</th>\n",
       "      <th>Size</th>\n",
       "      <th>Air</th>\n",
       "      <th>MPG</th>\n",
       "      <th>MPD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>92</td>\n",
       "      <td>86.892</td>\n",
       "      <td>7.868</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.496</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.662</td>\n",
       "      <td>1.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>89</td>\n",
       "      <td>98.623</td>\n",
       "      <td>7.979</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.391</td>\n",
       "      <td>1.510</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.619</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>86</td>\n",
       "      <td>92.785</td>\n",
       "      <td>7.535</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.529</td>\n",
       "      <td>0.022</td>\n",
       "      <td>1.589</td>\n",
       "      <td>1.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>72</td>\n",
       "      <td>105.119</td>\n",
       "      <td>7.506</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1.510</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1.567</td>\n",
       "      <td>1.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>93</td>\n",
       "      <td>84.775</td>\n",
       "      <td>7.821</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.337</td>\n",
       "      <td>1.479</td>\n",
       "      <td>0.054</td>\n",
       "      <td>1.584</td>\n",
       "      <td>1.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>99</td>\n",
       "      <td>93.382</td>\n",
       "      <td>7.787</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.338</td>\n",
       "      <td>1.508</td>\n",
       "      <td>0.059</td>\n",
       "      <td>1.759</td>\n",
       "      <td>1.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>95</td>\n",
       "      <td>97.727</td>\n",
       "      <td>7.651</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.340</td>\n",
       "      <td>1.467</td>\n",
       "      <td>0.032</td>\n",
       "      <td>1.947</td>\n",
       "      <td>1.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>95</td>\n",
       "      <td>99.444</td>\n",
       "      <td>7.645</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.346</td>\n",
       "      <td>1.405</td>\n",
       "      <td>0.034</td>\n",
       "      <td>1.982</td>\n",
       "      <td>1.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>102</td>\n",
       "      <td>82.742</td>\n",
       "      <td>7.599</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.348</td>\n",
       "      <td>1.343</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.061</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>103</td>\n",
       "      <td>71.567</td>\n",
       "      <td>7.718</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.078</td>\n",
       "      <td>2.215</td>\n",
       "      <td>1.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>116</td>\n",
       "      <td>62.030</td>\n",
       "      <td>8.349</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1.286</td>\n",
       "      <td>0.094</td>\n",
       "      <td>2.363</td>\n",
       "      <td>1.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>110</td>\n",
       "      <td>61.893</td>\n",
       "      <td>8.831</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1.277</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.440</td>\n",
       "      <td>1.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>115</td>\n",
       "      <td>67.878</td>\n",
       "      <td>8.821</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1.276</td>\n",
       "      <td>0.126</td>\n",
       "      <td>2.601</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>113</td>\n",
       "      <td>85.933</td>\n",
       "      <td>8.870</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.293</td>\n",
       "      <td>0.129</td>\n",
       "      <td>2.469</td>\n",
       "      <td>2.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>136</td>\n",
       "      <td>78.143</td>\n",
       "      <td>8.938</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.265</td>\n",
       "      <td>0.140</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>130</td>\n",
       "      <td>83.756</td>\n",
       "      <td>9.382</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.379</td>\n",
       "      <td>1.249</td>\n",
       "      <td>0.176</td>\n",
       "      <td>2.416</td>\n",
       "      <td>2.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>143</td>\n",
       "      <td>67.667</td>\n",
       "      <td>9.965</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.246</td>\n",
       "      <td>0.229</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>150</td>\n",
       "      <td>67.078</td>\n",
       "      <td>10.069</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.396</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.237</td>\n",
       "      <td>2.334</td>\n",
       "      <td>2.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>147</td>\n",
       "      <td>62.914</td>\n",
       "      <td>10.321</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.406</td>\n",
       "      <td>1.259</td>\n",
       "      <td>0.289</td>\n",
       "      <td>2.310</td>\n",
       "      <td>2.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>131</td>\n",
       "      <td>66.377</td>\n",
       "      <td>10.337</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.419</td>\n",
       "      <td>1.270</td>\n",
       "      <td>0.308</td>\n",
       "      <td>2.270</td>\n",
       "      <td>2.852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_models        Q       P    Dom  Japan     Eu  HP_Wt   Size    Air  \\\n",
       "year                                                                          \n",
       "71            92   86.892   7.868  0.866  0.057  0.077  0.490  1.496  0.000   \n",
       "72            89   98.623   7.979  0.892  0.042  0.066  0.391  1.510  0.014   \n",
       "73            86   92.785   7.535  0.932  0.040  0.028  0.364  1.529  0.022   \n",
       "74            72  105.119   7.506  0.887  0.050  0.064  0.347  1.510  0.026   \n",
       "75            93   84.775   7.821  0.853  0.083  0.064  0.337  1.479  0.054   \n",
       "76            99   93.382   7.787  0.876  0.081  0.043  0.338  1.508  0.059   \n",
       "77            95   97.727   7.651  0.837  0.112  0.051  0.340  1.467  0.032   \n",
       "78            95   99.444   7.645  0.855  0.107  0.039  0.346  1.405  0.034   \n",
       "79           102   82.742   7.599  0.803  0.158  0.038  0.348  1.343  0.047   \n",
       "80           103   71.567   7.718  0.773  0.191  0.036  0.350  1.296  0.078   \n",
       "81           116   62.030   8.349  0.741  0.213  0.046  0.349  1.286  0.094   \n",
       "82           110   61.893   8.831  0.714  0.235  0.051  0.347  1.277  0.134   \n",
       "83           115   67.878   8.821  0.734  0.215  0.051  0.351  1.276  0.126   \n",
       "84           113   85.933   8.870  0.783  0.179  0.038  0.361  1.293  0.129   \n",
       "85           136   78.143   8.938  0.761  0.191  0.048  0.372  1.265  0.140   \n",
       "86           130   83.756   9.382  0.733  0.216  0.050  0.379  1.249  0.176   \n",
       "87           143   67.667   9.965  0.702  0.245  0.052  0.395  1.246  0.229   \n",
       "88           150   67.078  10.069  0.717  0.237  0.045  0.396  1.251  0.237   \n",
       "89           147   62.914  10.321  0.690  0.261  0.049  0.406  1.259  0.289   \n",
       "90           131   66.377  10.337  0.682  0.276  0.043  0.419  1.270  0.308   \n",
       "\n",
       "        MPG    MPD  \n",
       "year                \n",
       "71    1.662  1.849  \n",
       "72    1.619  1.875  \n",
       "73    1.589  1.818  \n",
       "74    1.567  1.452  \n",
       "75    1.584  1.503  \n",
       "76    1.759  1.696  \n",
       "77    1.947  1.835  \n",
       "78    1.982  1.929  \n",
       "79    2.061  1.657  \n",
       "80    2.215  1.466  \n",
       "81    2.363  1.559  \n",
       "82    2.440  1.817  \n",
       "83    2.601  2.087  \n",
       "84    2.469  2.117  \n",
       "85    2.261  2.024  \n",
       "86    2.416  2.856  \n",
       "87    2.327  2.789  \n",
       "88    2.334  2.919  \n",
       "89    2.310  2.806  \n",
       "90    2.270  2.852  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# round the table to 3 digits to emulate the paper\n",
    "np.round(table_1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbd801f",
   "metadata": {},
   "source": [
    "#### Table III: Results with Logit Demand and Marginal Cost Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d352c",
   "metadata": {},
   "source": [
    "1. The first column shows the result of the OLS logit demand:\n",
    "\\begin{align}\n",
    "ln(s_j)-ln(s_0) = -\\alpha p_j + x_j'\\beta + \\xi_j\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5528185d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.07300751,  -0.12309488,  -0.03441478,   0.26546568,\n",
       "         2.34191416,  -0.08860627])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table 3 column 1\n",
    "table3_col1 = LinearRegression().fit(df[[\"hpwt\", \"air\", \"mpd\", \"space\", \"price\"]], df.diff_2)\n",
    "np.hstack((table3_col1.intercept_, table3_col1.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3070cc8",
   "metadata": {},
   "source": [
    "2. The second column shows the result of IV logit demand: (we use 2-step GMM for estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a136646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.27629294,  1.94935115,  1.28739148,  0.05456147,  2.35760254,\n",
       "       -0.21578695])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IV Reg in table 3 column 2\n",
    "\n",
    "tempDemand = gen_iv(X, firms, unique_mkts, markets)\n",
    "tempSupply = gen_iv(W, firms, unique_mkts, markets)\n",
    "\n",
    "Z = np.hstack((X, tempDemand[0], tempDemand[1]))\n",
    "baseData = np.hstack((p.reshape((-1,1)), X))\n",
    "\n",
    "Z_s = np.hstack((W, tempSupply[0], tempSupply[1], df.mpd.values.reshape((-1,1))))\n",
    "\n",
    "X_base = np.hstack((X, p.reshape((-1,1))))\n",
    "\n",
    "ZX = Z.T @ X_base\n",
    "\n",
    "bx1 = np.linalg.inv(ZX.T @ ZX)@ ZX.T @ Z.T @ delta_0 # first round IV regression using identity weighting matrix\n",
    "\n",
    "e = delta_0 - X_base @ bx1 # obtain the residual\n",
    "\n",
    "g_ind = e.reshape((-1,1)) * Z\n",
    "\n",
    "demean = g_ind - g_ind.mean(axis=0).reshape((1,-1))\n",
    "\n",
    "vg = demean.T @ demean / demean.shape[0] # this is actually the variance of g\n",
    "\n",
    "w0 = np.linalg.inv(vg) # obtain feasible optimal weighting matrix\n",
    "\n",
    "table3_col2 = np.linalg.inv(ZX.T @ w0 @ ZX) @ ZX.T @ w0 @ Z.T @ delta_0 # second round IV regression\n",
    "table3_col2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034431d5",
   "metadata": {},
   "source": [
    "3. The third column shows the result of OLS ln(price) on $w$:\n",
    "\\begin{align}\n",
    "ln(p) = w'\\gamma + \\omega\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921bc552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.88192125,  0.52033668,  0.6797513 , -0.47064027,  0.12482708,\n",
       "        0.01283075])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# table 3 column 3\n",
    "table3_col3 = LinearRegression().fit(\n",
    "    df[[\"ln_hpwt\", \"air\", \"ln_mpg\", \"ln_space\", \"trend\"]],\n",
    "    df.ln_price)\n",
    "np.hstack((table3_col3.intercept_, table3_col3.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465d13b",
   "metadata": {},
   "source": [
    "#### Table IV: Esimated Parameters of the Demand and Pricing Equations (column 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0626496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain block-diag matrix of supply and demand instruments\n",
    "z = scipy.linalg.block_diag(Z,Z_s)\n",
    "\n",
    "# Recommended initial weighting matrix from Aviv's appendix\n",
    "w1 = np.linalg.inv(z.T @ z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c252029",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.475566625595093"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # run objective function once to see if it is working\n",
    "# initial parameter guess (from BLP(1995))\n",
    "theta_2 = [3.612, 4.628, 1.818, 1.050, 2.056, 43.501]\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "obj = objective(theta_2, \n",
    "                df.share.values, \n",
    "                X, V, p, y_it, J, T, N, unique_mkts, markets, 1e-4, \n",
    "              Z, Z_s, W, w1, firms)\n",
    "\n",
    "\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ff81cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.45681858062744"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constraints for the minimization problem\n",
    "#  not needed because utility considers abosolute value of params before calculating\n",
    "\n",
    "# search over parameters that minimize the objective function\n",
    "t1 = time.time()\n",
    "\n",
    "# set bounds for optimization (not entirely needed but oh well)\n",
    "bnds = ((0,np.inf), (0,np.inf), (0,np.inf), \n",
    "        (0,np.inf), (0,np.inf), (5,np.inf))\n",
    "\n",
    "res_init_wt = minimize(objective,\n",
    "                      theta_2, \n",
    "                      args = (df.share.values, X, V, p, y_it, \n",
    "                              J, T, N, unique_mkts, markets, 1e-4, \n",
    "                              Z, Z_s, W, w1, firms), \n",
    "                      bounds = bnds,\n",
    "                      method = \"L-BFGS-B\",\n",
    "                      options = {'maxiter': 1000, 'maxfun': 1000, 'eps': 1e-3},\n",
    "                      tol = 1e-4)\n",
    "    \n",
    "\n",
    "    \n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aedcaf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "# outfile = open(\"res_init_wt_bfgs.pickle\", \"wb\")\n",
    "# pickle.dump(res_init_wt, outfile)\n",
    "# outfile.close()\n",
    "\n",
    "# Reading\n",
    "with open(\"res_init_wt_bfgs.pickle\", \"rb\") as infile:\n",
    "    res_init_wt = pickle.load(infile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "decbd235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.612,  4.628,  1.818,  1.05 ,  2.056, 43.501])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_init_wt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68b021e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = np.sum(J)\n",
    "\n",
    "# approximate optimal weighting matrix\n",
    "params_2 = res_init_wt.x\n",
    "\n",
    "# calculate mean utility given the optimal parameters (with id weighting matrix)\n",
    "d.delta = solve_delta(df.share.values, X, V, p, y_it, \n",
    "                        d.delta, params_2, J, T, N, 1e-5)\n",
    "\n",
    "# calculate probabilities and shares given the optimal params (w/ id weight matrix)\n",
    "q_s = compute_share(X, V, p, y_it, d.delta, params_2, J, T, N)\n",
    "\n",
    "# calculate marginal costs\n",
    "mc = calc_mc(q_s, firms, p, y_it, params_2[5], J, T, N, unique_mkts, markets).reshape((-1,1))\n",
    "\n",
    "y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))\n",
    "x = scipy.linalg.block_diag(X,W)\n",
    "z = scipy.linalg.block_diag(Z,Z_s)\n",
    "\n",
    "# this is the first order condition that solves for the linear parameters\n",
    "b = np.linalg.inv(x.T @ z @ w1 @ z.T @ x) @ (x.T @ z @ w1 @ z.T @ y2)\n",
    "\n",
    "# obtain the error\n",
    "xi_w = y2 - x @ b\n",
    "\n",
    "\n",
    "# update weighting matrix\n",
    "g_ind = z * xi_w\n",
    "vg = g_ind.T @ g_ind / obs\n",
    "\n",
    "# obtain optimal weighting matrix\n",
    "weight = scipy.linalg.inv(vg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43c782ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.10295414924622"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now search for optimal parameters with the optimal weighting matrix\n",
    "t1 = time.time()\n",
    "\n",
    "res = minimize(objective,\n",
    "              theta_2, \n",
    "              args = (df.share.values, X, V, p, y_it, \n",
    "                      J, T, N, unique_mkts, markets, 1e-4, \n",
    "                      Z, Z_s, W, weight, firms), \n",
    "              bounds = bnds,\n",
    "              method = \"L-BFGS-B\",\n",
    "              options = {'maxiter': 1000, 'maxfun': 1000, 'eps': 1e-3},\n",
    "              tol = 1e-4)\n",
    "\n",
    "time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6841bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "#outfile = open(\"res_bfgs.pickle\", \"wb\")\n",
    "#pickle.dump(res_init_wt, outfile)\n",
    "#outfile.close()\n",
    "\n",
    "# Reading\n",
    "with open(\"res_bfgs.pickle\", \"rb\") as infile:\n",
    "    res_init_wt = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9131a",
   "metadata": {},
   "source": [
    "1. Non-linear parameter estimates: Std. Deviations ($\\sigma_\\beta$'s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06ebbaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.48567094,  4.73803617,  1.85556832,  1.04868037,  2.30903141,\n",
       "       43.49958848])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_3 = res.x\n",
    "params_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac8cc33",
   "metadata": {},
   "source": [
    "2. Linear parameters:\n",
    "\n",
    "First 5 are the demand side means (Constant, HP/Weight, Air, MP$, Size)\n",
    "\n",
    "Last 6 are the cost side params (Constant, ln(HP/Weight), Air, ln(MPG), ln(Size), Trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "423b6629",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.delta = solve_delta(df.share.values, X, V, p, y_it, \n",
    "                        d.delta, params_3, J, T, N, 1e-4)\n",
    "q_s = compute_share(X, V, p, y_it, d.delta, params_3, J, T, N)\n",
    "    \n",
    "mc = calc_mc(q_s, firms, p, y_it, params_3[5], J, T, N, unique_mkts, markets).reshape((-1,1))\n",
    "    \n",
    "y2 = np.vstack((d.delta.reshape((-1,1)), np.log(mc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bc99f4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.42322037],\n",
       "       [ 3.01177244],\n",
       "       [ 0.56620007],\n",
       "       [-0.17486551],\n",
       "       [ 3.30623812],\n",
       "       [ 1.19084377],\n",
       "       [ 0.50412849],\n",
       "       [ 0.59499734],\n",
       "       [-0.45676616],\n",
       "       [-0.2029649 ],\n",
       "       [ 0.01709775]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear parameters\n",
    "# compare parameters to Table iv, column 3\n",
    "#  first 5 are the demand side means (Constant, HPWT, Air, MP$, Size)\n",
    "#  last 6 are the cost side params (Constant, ln(HPWT), Air, ln(MPG), ln(Size), Trend)\n",
    "b = np.linalg.inv(x.T @ z @ weight @ z.T @ x) @ (x.T @ z @ weight @ z.T @ y2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b865cc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.48567094,  4.73803617,  1.85556832,  1.04868037,  2.30903141,\n",
       "       43.49958848])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-linear parameters - these are the sigma estimates and alpha in table iv of BLP\n",
    "# (constant, HPWT, Air, MP$, Size, ln(y-p))\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f23f8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3134736956736436"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average markup (compare to table 12 of Conlon and Gortmaker (2019))\n",
    "np.mean((p.flatten() - mc.flatten())/p.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de895ca2",
   "metadata": {},
   "source": [
    "#### Table VI: Own- and Cross-Price Semi-Elasticities:\n",
    "\n",
    "(the change of percentage market share given the  \\$1k price change)\n",
    "\n",
    "$\\epsilon_{ij} = \\frac{\\partial s_i}{\\partial p_j} \\cdot \\frac{100}{s_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f21c371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "share_deriv = []\n",
    "q = q_s[0]\n",
    "s = q_s[1]\n",
    "for m in unique_mkts:\n",
    "    # obtain list of firms operating in that market/year\n",
    "    firm_yr = firms[markets == m]\n",
    "\n",
    "    # obtain list of prices of goods in that market/year\n",
    "    price = p[markets == m]\n",
    "\n",
    "    # J_t x J_t block matrix of 1's indicating goods belonging to same firm\n",
    "    #  in that market/year\n",
    "    # Also known as the ownership matrix\n",
    "    same_firm = np.equal(firm_yr, np.transpose(firm_yr))\n",
    "\n",
    "    # obtain matrix of probabilities for all simulations for goods in that \n",
    "    #  market/year\n",
    "    yr = q[markets == m,:]\n",
    "\n",
    "    # obtain number of goods in that market\n",
    "    nobs = np.size(yr, 0)\n",
    "\n",
    "    # this is the omega matrix initializing        \n",
    "    deriv_m = np.zeros((nobs, nobs))\n",
    "\n",
    "    # calculate the omega matix by iterating through all individuals\n",
    "    #  Omega matrix is cross-price share deriv element-wise product with ownership matrix\n",
    "    for i in range(N):\n",
    "        yr_i = yr[:, i].reshape((-1, 1))\n",
    "        deriv_m += params_3[5] / y_it[i, m - 1] * 1/N * (yr_i @ yr_i.T - np.diag(yr[:,i]))\n",
    "        \n",
    "    share_deriv.append(deriv_m)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28daf017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the mazda 323 own-price deriv in 1990\n",
    "mz323_deriv = (share_deriv[19][df.modelvec[markets == 20] == \"MZ323\"]).flatten()[df.modelvec[markets == 20] == \"MZ323\"]\n",
    "\n",
    "# obtain the bmw 735i own-price deriv in 1990\n",
    "bw735i_deriv = (share_deriv[19][df.modelvec[markets == 20] == \"BW735i\"]).flatten()[df.modelvec[markets == 20] == \"BW735i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a3dd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the mazda 323 mkt share in 1990\n",
    "mz323_s = s[(markets == 20) & (df.modelvec == \"MZ323\")]\n",
    "\n",
    "# obtain the bmw 735i market share in 1990\n",
    "bw735i_s = s[(markets == 20) & (df.modelvec == \"BW735i\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d91344d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-127.47253219])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with table VI, first row first column of BLP\n",
    "mz323_deriv/ mz323_s * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c97802eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.18013863])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with table VI, last row last column of BLP\n",
    "bw735i_deriv/bw735i_s * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9db97a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create all of table VI\n",
    "# extract all of the cars\n",
    "table_vi_cars = [\"MZ323\", \"NISENT\", \"FDESCO\", \"CVCAVA\", \"HDACCO\", \"FDTAUR\", \"BKCENT\",\n",
    "                \"NIMAXI\", \"ACLEGE\", \"LNTOWN\", \"CDSEVI\", \"LXLS40\", \"BW735i\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "590708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain share derivs and shares relevant cars in 1990\n",
    "deriv_1990 = share_deriv[19]\n",
    "s_1990 = s[markets == 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c45f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the matrix dimensions of table VI\n",
    "table_vi_mx = np.zeros((len(table_vi_cars), len(table_vi_cars)))\n",
    "\n",
    "# iterate across cars to obtain table vi\n",
    "row = 0\n",
    "for car in table_vi_cars:\n",
    "    col = 0\n",
    "    for cars in table_vi_cars:\n",
    "        table_vi_mx[row, col] = (deriv_1990[df.modelvec[markets == 20] == cars].flatten())[df.modelvec[markets == 20] == car] / \\\n",
    "            s_1990[df.modelvec[markets == 20] == car] * 100\n",
    "        col += 1\n",
    "    row += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3f8a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in dataframe for easier viewing\n",
    "table_vi = pd.DataFrame(np.round(table_vi_mx, 3))\n",
    "\n",
    "# renaming rows and columns\n",
    "table_vi.index = table_vi_cars\n",
    "table_vi.columns = table_vi_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "402bea9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MZ323</th>\n",
       "      <th>NISENT</th>\n",
       "      <th>FDESCO</th>\n",
       "      <th>CVCAVA</th>\n",
       "      <th>HDACCO</th>\n",
       "      <th>FDTAUR</th>\n",
       "      <th>BKCENT</th>\n",
       "      <th>NIMAXI</th>\n",
       "      <th>ACLEGE</th>\n",
       "      <th>LNTOWN</th>\n",
       "      <th>CDSEVI</th>\n",
       "      <th>LXLS40</th>\n",
       "      <th>BW735i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MZ323</th>\n",
       "      <td>-127.473</td>\n",
       "      <td>1.527</td>\n",
       "      <td>9.282</td>\n",
       "      <td>7.466</td>\n",
       "      <td>2.290</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISENT</th>\n",
       "      <td>0.710</td>\n",
       "      <td>-111.663</td>\n",
       "      <td>8.791</td>\n",
       "      <td>7.058</td>\n",
       "      <td>2.550</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDESCO</th>\n",
       "      <td>0.740</td>\n",
       "      <td>1.508</td>\n",
       "      <td>-104.297</td>\n",
       "      <td>6.992</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CVCAVA</th>\n",
       "      <td>0.582</td>\n",
       "      <td>1.184</td>\n",
       "      <td>6.840</td>\n",
       "      <td>-105.263</td>\n",
       "      <td>2.600</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDACCO</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.303</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1.839</td>\n",
       "      <td>-48.370</td>\n",
       "      <td>1.677</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDTAUR</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.828</td>\n",
       "      <td>1.319</td>\n",
       "      <td>2.233</td>\n",
       "      <td>-45.357</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BKCENT</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.188</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1.415</td>\n",
       "      <td>1.425</td>\n",
       "      <td>1.368</td>\n",
       "      <td>-57.430</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIMAXI</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.313</td>\n",
       "      <td>1.043</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.815</td>\n",
       "      <td>-31.784</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACLEGE</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.481</td>\n",
       "      <td>-18.070</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LNTOWN</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.158</td>\n",
       "      <td>-11.275</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDSEVI</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.550</td>\n",
       "      <td>-12.829</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LXLS40</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.139</td>\n",
       "      <td>-10.266</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BW735i</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-7.180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MZ323   NISENT   FDESCO   CVCAVA  HDACCO  FDTAUR  BKCENT  NIMAXI  \\\n",
       "MZ323  -127.473    1.527    9.282    7.466   2.290   0.893   0.391   0.060   \n",
       "NISENT    0.710 -111.663    8.791    7.058   2.550   1.017   0.426   0.079   \n",
       "FDESCO    0.740    1.508 -104.297    6.992   2.600   0.899   0.392   0.067   \n",
       "CVCAVA    0.582    1.184    6.840 -105.263   2.600   1.400   0.538   0.106   \n",
       "HDACCO    0.126    0.303    1.799    1.839 -48.370   1.677   0.383   0.250   \n",
       "FDTAUR    0.066    0.161    0.828    1.319   2.233 -45.357   0.490   0.279   \n",
       "BKCENT    0.080    0.188    1.010    1.415   1.425   1.368 -57.430   0.727   \n",
       "NIMAXI    0.014    0.039    0.193    0.313   1.043   0.875   0.815 -31.784   \n",
       "ACLEGE    0.003    0.011    0.050    0.088   0.641   0.564   0.284   0.481   \n",
       "LNTOWN    0.001    0.003    0.014    0.031   0.291   0.348   0.120   0.218   \n",
       "CDSEVI    0.001    0.005    0.020    0.040   0.380   0.394   0.146   0.319   \n",
       "LXLS40    0.001    0.004    0.019    0.032   0.345   0.300   0.098   0.237   \n",
       "BW735i    0.000    0.001    0.005    0.012   0.150   0.167   0.052   0.146   \n",
       "\n",
       "        ACLEGE  LNTOWN  CDSEVI  LXLS40  BW735i  \n",
       "MZ323    0.007   0.006   0.002   0.002   0.000  \n",
       "NISENT   0.012   0.010   0.003   0.003   0.000  \n",
       "FDESCO   0.009   0.007   0.002   0.003   0.000  \n",
       "CVCAVA   0.016   0.015   0.005   0.004   0.000  \n",
       "HDACCO   0.083   0.104   0.030   0.034   0.004  \n",
       "FDTAUR   0.097   0.165   0.042   0.039   0.006  \n",
       "BKCENT   0.136   0.159   0.043   0.036   0.005  \n",
       "NIMAXI   0.258   0.324   0.106   0.098   0.015  \n",
       "ACLEGE -18.070   0.438   0.153   0.149   0.030  \n",
       "LNTOWN   0.158 -11.275   0.123   0.156   0.035  \n",
       "CDSEVI   0.248   0.550 -12.829   0.173   0.040  \n",
       "LXLS40   0.195   0.565   0.139 -10.266   0.047  \n",
       "BW735i   0.152   0.497   0.128   0.183  -7.180  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_vi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7cfbeb",
   "metadata": {},
   "source": [
    "### Citations\n",
    "\n",
    "Berry, S., Levinsohn, J., & Pakes, A. (1995). Automobile prices in market equilibrium. Econometrica: Journal of the Econometric Society, 841-890.\n",
    "\n",
    "Nevo, A. (2000). A practitioner's guide to estimation of randomâ€coefficients logit models of demand. Journal of economics & management strategy, 9(4), 513-548.\n",
    "\n",
    "Ivan Li's website: Replication of the classic BLP (1995). Retrieved June, 2023, from https://www.ivan-li.com/code/blp_1995"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
